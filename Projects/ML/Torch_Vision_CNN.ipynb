{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "19b930b8-ea5e-4289-b01f-a4c8d17a694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7d18200b-2a83-412f-add9-9581384f23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra block 4 testing\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "folder = '/home/tom/apps/python-envs/data/stop'\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    #print(filename)\n",
    "    img_path = os.path.join(folder, filename)\n",
    "    \n",
    "    # Attempt to load the image\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # Check if the image is loaded successfully\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "        \n",
    "        # Use 'stop' in img_path instead of 'stop' in folder\n",
    "        labels.append(1 if 'stop' in img_path else 0)\n",
    "    else:\n",
    "        print(f\"Error loading image: {img_path}\")\n",
    "\n",
    "# Now, 'images' and 'labels' should contain your processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9607feab-6a2d-45dd-8665-21d0a9a28913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=5, padding=2), # input = 3 meaning R, G and B\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(128 * 14 * 14, 2) # 14 here because 224 (input dimension of image) / 2 * 4 (pooling size * number of layers), there is 2 output (0 for not_stop and 1 for stop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6b4b6344-ee1e-470e-9740-3c47ded895d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from a folder\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "        labels.append(1 if folder == '/home/tom/apps/python-envs/data/stop' else 0)  # 1 for stop, 0 for not stop\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b40b45d4-524c-4dbe-be7a-48b21d8a3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels\n",
    "stop_images, stop_labels = load_images('/home/tom/apps/python-envs/data/stop')\n",
    "not_stop_images, not_stop_labels = load_images('/home/tom/apps/python-envs/data/not_stop')\n",
    "\n",
    "# Combine stop and not_stop images\n",
    "images = np.concatenate((stop_images, not_stop_images), axis=0)\n",
    "labels = np.concatenate((stop_labels, not_stop_labels), axis=0)\n",
    "\n",
    "# Define transformations and create a DataLoader\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "# Convert images to PyTorch tensors and normalize\n",
    "image_tensors = torch.tensor(images.transpose((0, 3, 1, 2)), dtype=torch.float32) / 255.0\n",
    "label_tensors = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = torch.utils.data.TensorDataset(image_tensors, label_tensors)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e9268b33-4778-40fb-86ba-e75370e229f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6888\n",
      "Epoch [2/10], Loss: 0.6861\n",
      "Epoch [3/10], Loss: 0.5488\n",
      "Epoch [4/10], Loss: 2.2374\n",
      "Epoch [5/10], Loss: 0.5674\n",
      "Epoch [6/10], Loss: 0.4837\n",
      "Epoch [7/10], Loss: 0.4307\n",
      "Epoch [8/10], Loss: 0.3664\n",
      "Epoch [9/10], Loss: 0.3719\n",
      "Epoch [10/10], Loss: 0.0396\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # is it better to use bce loss for binary classification?\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # You can adjust this based on your dataset size and convergence\n",
    "for epoch in range(num_epochs):\n",
    "    for images_batch, labels_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "969e881f-e93d-463b-b618-18f8b504e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict and classify an image\n",
    "def classify_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to match the input size of the model\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # Convert the image to RGB color format\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert the image to a PyTorch tensor and normalize\n",
    "    img_tensor = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32) / 255.0\n",
    "    \n",
    "    # Add an extra dimension to represent the batch (single image in this case)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    # Disable gradient calculation during inference\n",
    "    with torch.no_grad():\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Perform forward pass to get the output predictions\n",
    "        output = model(img_tensor)\n",
    "        \n",
    "        # Get the predicted class index\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        # Return the predicted class index as an integer\n",
    "        return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "58d3cfe2-a86d-4000-93f2-92c8e1e2270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Image Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the base directory for images\n",
    "base_image_dir = '/home/tom/apps/python-envs/data/'\n",
    "\n",
    "# Test the classifier on an additional image\n",
    "test_image_prediction = classify_image(os.path.join(base_image_dir, '4.png'))\n",
    "\n",
    "print(\"Test Image Prediction:\", test_image_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f5e81-8889-49db-9dcf-162b7f38b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need of this block (use if you want percentage)\n",
    "\n",
    "\n",
    "# Define the base directory for images\n",
    "base_image_dir = '/home/tom/apps/python-envs/data/'\n",
    "base_image_dir_stop = '/home/tom/apps/python-envs/data/stop'\n",
    "base_image_dir_not_stop = '/home/tom/apps/python-envs/data/not_stop'\n",
    "\n",
    "# Test the classifier on an additional image\n",
    "test_image_prediction = classify_image(os.path.join(base_image_dir, '4.png'))\n",
    "print(\"Test Image Prediction:\", test_image_prediction)\n",
    "\n",
    "# Get a list of all image filenames in the 'stop' directory\n",
    "stop_image_filenames = [filename for filename in os.listdir(base_image_dir_stop) if filename.endswith('.jpg')]\n",
    "\n",
    "# Actual labels for 'stop' images\n",
    "actual_labels_stop = [1] * len(stop_image_filenames)\n",
    "\n",
    "# Classify each 'stop' image and store the predictions\n",
    "stop_images_pred = []\n",
    "\n",
    "for filename in stop_image_filenames:\n",
    "    image_path = os.path.join(base_image_dir_stop, filename)\n",
    "    prediction = classify_image(image_path)\n",
    "    stop_images_pred.append(prediction)\n",
    "\n",
    "# Get a list of all image filenames in the 'not_stop' directory\n",
    "not_stop_image_filenames = [filename for filename in os.listdir(base_image_dir_not_stop) if filename.endswith('.jpg')]\n",
    "\n",
    "# Actual labels for 'not_stop' images\n",
    "actual_labels_not_stop = [0] * len(not_stop_image_filenames)\n",
    "\n",
    "# Classify each 'not_stop' image and store the predictions\n",
    "not_stop_images_pred = []\n",
    "\n",
    "for filename in not_stop_image_filenames:\n",
    "    image_path = os.path.join(base_image_dir_not_stop, filename)\n",
    "    prediction = classify_image(image_path)\n",
    "    not_stop_images_pred.append(prediction)\n",
    "\n",
    "# Calculate accuracy for 'stop' images\n",
    "correct_predictions_stop = sum([1 for pred, actual in zip(stop_images_pred, actual_labels_stop) if pred == actual])\n",
    "total_images_stop = len(stop_image_filenames)\n",
    "accuracy_stop = correct_predictions_stop / total_images_stop\n",
    "\n",
    "# Calculate accuracy for 'not_stop' images\n",
    "correct_predictions_not_stop = sum([1 for pred, actual in zip(not_stop_images_pred, actual_labels_not_stop) if pred == actual])\n",
    "total_images_not_stop = len(not_stop_image_filenames)\n",
    "accuracy_not_stop = correct_predictions_not_stop / total_images_not_stop\n",
    "\n",
    "# Display the predictions and accuracy for 'stop' images\n",
    "print(\"Predictions for 'stop' images:\")\n",
    "for filename, prediction in zip(stop_image_filenames, stop_images_pred):\n",
    "    print(f\"Image '{filename}': Prediction {prediction}\")\n",
    "\n",
    "print(f\"Accuracy on 'stop' images: {accuracy_stop * 100:.2f}%\")\n",
    "\n",
    "# Display the predictions and accuracy for 'not_stop' images\n",
    "print(\"\\nPredictions for 'not_stop' images:\")\n",
    "for filename, prediction in zip(not_stop_image_filenames, not_stop_images_pred):\n",
    "    print(f\"Image '{filename}': Prediction {prediction}\")\n",
    "\n",
    "print(f\"Accuracy on 'not_stop' images: {accuracy_not_stop * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe71310-4cef-4809-96f3-9ce305593449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
