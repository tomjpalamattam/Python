{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa06549-21f9-4dbb-9310-fb4401c1cabc",
   "metadata": {},
   "source": [
    "# Making Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7e5b36-c60b-4be1-9d07-8894633a588d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 14:21:59.462603: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-14 14:22:00.809616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac90f10-22ff-4df7-a777-76b15353b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read the file content\n",
    "with open('swap_adaptaion_var.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Find all 2D arrays using regular expressions\n",
    "arrays = re.findall(r'\\[\\[.*?\\]\\]', content, re.DOTALL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827173f7-f032-4c4a-bf6a-1bae398709e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up each array and convert to NumPy array format\n",
    "cleaned_arrays = []\n",
    "for array in arrays:\n",
    "    # Remove the leading and trailing double brackets\n",
    "    array = array[2:-2].strip()\n",
    "    # Split into rows and clean up spaces\n",
    "    rows = [row.strip() for row in array.split(']\\n [')]\n",
    "    # Convert string rows to list of lists\n",
    "    rows = [row.split() for row in rows]\n",
    "    # Handle elements to remove single quotes from strings\n",
    "    rows = [[el.strip(\"'\") if el.startswith(\"'\") and el.endswith(\"'\") else el for el in row] for row in rows]\n",
    "    # Convert to NumPy array with dtype=object\n",
    "    np_array = np.array(rows, dtype=object)\n",
    "    cleaned_arrays.append(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784cc18b-40d3-4f7c-bc10-6fed2c6b8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_data = cleaned_arrays[962]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3a3a49-ca67-434d-b344-83a81bad2f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['B1', 'B12', 'B14', '0', '0'],\n",
       "       ['B2', 'B13', 'B15', '0', '0'],\n",
       "       ['B5', '0', 'B16', '0', '0'],\n",
       "       ['B4', '0', 'B17', '0', '0'],\n",
       "       ['B3', '0', 'B18', '0', '0'],\n",
       "       ['B6', '0', 'B19', '0', '0'],\n",
       "       ['B7', '0', 'B20', '0', '0'],\n",
       "       ['B8', '0', '0', '0', '0'],\n",
       "       ['0', 'B9', '0', '0', '0'],\n",
       "       ['0', 'B10', '0', '0', '0'],\n",
       "       ['0', 'B11', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6e65ba-c486-49b3-b743-8eeabdf75653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialRunApp:\n",
    "    def __init__(self, root, grid_data, trial_runs):\n",
    "        self.root = root\n",
    "        self.root.title(\"Trial Run App\")\n",
    "        \n",
    "        self.grid_data = grid_data\n",
    "        self.trial_runs = trial_runs\n",
    "        self.current_trial = 1\n",
    "        self.usage_history = []\n",
    "        self.frequency = defaultdict(int)\n",
    "        self.last_click_time = None  # Variable to store the time of the last button click\n",
    "        \n",
    "        self.create_buttons()\n",
    "        \n",
    "        self.next_trial_button = tk.Button(root, text=\"Next Trial\", command=self.next_trial)\n",
    "        self.next_trial_button.grid(row=len(grid_data), column=0, columnspan=5)\n",
    "    \n",
    "    def create_buttons(self):\n",
    "        for r, row in enumerate(self.grid_data):\n",
    "            for c, cell in enumerate(row):\n",
    "                if cell != '0':\n",
    "                    button = tk.Button(self.root, text=cell, command=lambda t=cell: self.track_usage(t))\n",
    "                    button.grid(row=r, column=c, padx=5, pady=5)\n",
    "    \n",
    "    def track_usage(self, text):\n",
    "        current_time = datetime.now()\n",
    "        if self.last_click_time:\n",
    "            time_gap = (current_time - self.last_click_time).total_seconds()\n",
    "        else:\n",
    "            time_gap = 0  # First click\n",
    "        \n",
    "        self.last_click_time = current_time  # Update the last click time\n",
    "        \n",
    "        self.usage_history.append((self.current_trial, time_gap, text))\n",
    "        self.frequency[text] += 1\n",
    "        \n",
    "        print(f\"Button '{text}' clicked with a time gap of {time_gap:.2f} seconds from the previous click\")\n",
    "    \n",
    "    def next_trial(self):\n",
    "        if self.current_trial < self.trial_runs:\n",
    "            self.current_trial += 1\n",
    "            messagebox.showinfo(\"Trial\", f\"Starting Trial {self.current_trial}\")\n",
    "        else:\n",
    "            self.display_summary()\n",
    "            self.save_trial()\n",
    "    \n",
    "    def display_summary(self):\n",
    "        summary = \"Usage History:\\n\"\n",
    "        for trial, time_gap, text in self.usage_history:\n",
    "            summary += f\"Trial {trial}: Button '{text}' clicked with a time gap of {time_gap:.2f} seconds\\n\"\n",
    "        summary += \"\\nFrequency of Usage:\\n\"\n",
    "        for text, count in self.frequency.items():\n",
    "            summary += f\"'{text}': {count} times\\n\"\n",
    "        messagebox.showinfo(\"Summary\", summary)\n",
    "    \n",
    "    def save_trial(self):\n",
    "        with open(\"trial.txt\", \"w\") as file:\n",
    "            json.dump(self.usage_history, file)\n",
    "        print(\"Trial history saved to trial.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a879f5-79df-4431-846f-1d6291264c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "\n",
    "    trial_runs = simpledialog.askinteger(\"Input\", \"Enter number of trial runs:\")\n",
    "    \n",
    "    if trial_runs and trial_runs > 0:\n",
    "        app = TrialRunApp(root, grid_data, trial_runs)\n",
    "        root.mainloop()\n",
    "    else:\n",
    "        messagebox.showerror(\"Error\", \"Number of trial runs must be a positive integer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4d6a4-4dcb-4e09-a672-e12298ebe555",
   "metadata": {},
   "source": [
    "# Manualy append each ui_grid and trailhistory to dataframe df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ba5db4-9990-4833-b5e9-8a775b951b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['ui_grid', 'trial_history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad400c7-59eb-4a47-a715-ab473ed584b3",
   "metadata": {},
   "source": [
    "### Run the below block for every ui_elements and trial_history pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8cea946-7ce2-4feb-8dac-e08b38eddd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "\n",
    "ui_elements = [[[41, 328, 309, 348], \"B1\"], [[40, 348, 309, 369], \"B2\"], [[42, 379, 282, 397], \"B3\"], [[37, 403, 274, 426], \"B4\"], [[37, 427, 277, 455], \"B5\"], [[38, 453, 277, 473], \"B6\"], [[42, 477, 319, 498], \"B7\"], [[35, 501, 287, 526], \"B8\"], [[361, 322, 670, 350], \"B9\"], [[364, 350, 659, 375], \"B10\"], [[368, 375, 669, 409], \"B11\"], [[367, 519, 673, 551], \"B12\"], [[365, 548, 682, 577], \"B13\"], [[743, 321, 1014, 353], \"B14\"], [[737, 349, 1064, 380], \"B15\"], [[735, 380, 1046, 404], \"B16\"], [[739, 402, 1112, 425], \"B17\"], [[735, 425, 1105, 447], \"B18\"], [[732, 451, 1096, 478], \"B19\"], [[736, 474, 1117, 512], \"B20\"]]\n",
    "\n",
    "\n",
    "association_data = [\n",
    "    ('B1','B2','B3','B4','B5','B6','B7','B8'),\n",
    "    ('B9','B10','B11'),\n",
    "    ('B12','B13'),    \n",
    "    ('B14','B15','B16','B17','B18','B19','B20')\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#trial_history = [[1, 0, \"B1\"], [1, 2.86394, \"B2\"], [1, 2.199985, \"B4\"], [1, 2.096065, \"B5\"], [1, 1.999964, \"B7\"], [1, 2.039992, \"B7\"], [1, 1.903958, \"B1\"], [1, 3.399697, \"B2\"], [1, 3.640313, \"B6\"], [1, 4.751862, \"B9\"], [1, 2.303586, \"B9\"], [1, 2.880333, \"B10\"], [1, 2.752281, \"B10\"], [1, 2.087741, \"B11\"], [1, 1.607647, \"B11\"], [1, 2.999987, \"B12\"], [1, 1.832371, \"B12\"], [1, 6.375997, \"B13\"], [1, 3.15201, \"B16\"], [1, 4.24801, \"B18\"], [1, 2.83199, \"B17\"], [2, 8.040069, \"B1\"], [2, 2.096205, \"B2\"], [2, 2.967795, \"B3\"], [2, 2.791962, \"B3\"], [2, 4.816055, \"B7\"], [2, 2.407954, \"B7\"], [2, 1.880294, \"B8\"], [2, 3.223746, \"B9\"], [2, 9.624239, \"B10\"], [2, 1.127834, \"B10\"], [2, 0.72761, \"B11\"], [2, 6.264467, \"B13\"], [2, 2.391985, \"B13\"], [2, 3.568001, \"B16\"], [2, 5.024111, \"B17\"], [2, 5.728022, \"B19\"], [3, 22.808244, \"B1\"], [3, 2.680213, \"B2\"], [3, 5.872045, \"B3\"], [3, 6.151742, \"B7\"], [3, 2.504159, \"B7\"], [3, 3.600077, \"B5\"], [3, 4.128013, \"B4\"], [3, 3.448125, \"B9\"], [3, 2.719584, \"B9\"], [3, 2.59229, \"B10\"], [3, 1.464159, \"B10\"], [3, 2.591902, \"B11\"], [3, 2.112159, \"B11\"], [3, 3.247986, \"B12\"], [3, 2.663964, \"B13\"], [3, 3.200157, \"B17\"], [3, 3.439904, \"B18\"], [3, 1.97594, \"B19\"], [4, 5.040229, \"B1\"], [4, 1.823922, \"B1\"], [4, 2.144019, \"B2\"], [4, 1.864072, \"B2\"], [4, 1.879502, \"B3\"], [4, 5.384622, \"B7\"], [4, 2.072185, \"B6\"], [4, 1.999817, \"B5\"], [4, 5.848155, \"B9\"], [4, 3.727972, \"B9\"], [4, 1.599826, \"B10\"], [4, 1.863917, \"B10\"], [4, 1.815844, \"B11\"], [4, 4.663804, \"B11\"], [4, 4.343928, \"B12\"], [4, 3.232112, \"B16\"], [4, 2.007768, \"B14\"], [4, 2.800064, \"B17\"], [4, 3.263698, \"B18\"], [4, 0.959997, \"B19\"], [1, 0, \"B1\"], [1, 0.991919, \"B1\"], [1, 1.728294, \"B2\"], [1, 1.007718, \"B2\"], [1, 2.496078, \"B3\"], [1, 1.887591, \"B3\"], [1, 4.568456, \"B5\"], [1, 1.271956, \"B5\"], [1, 2.200197, \"B4\"], [1, 0.904022, \"B3\"], [1, 4.247272, \"B4\"], [1, 1.992533, \"B3\"], [1, 5.007584, \"B8\"], [1, 4.312557, \"B4\"], [1, 1.551942, \"B4\"], [1, 5.056073, \"B11\"], [1, 1.943945, \"B11\"], [1, 6.696079, \"B9\"], [1, 5.640163, \"B15\"], [1, 0.7119, \"B16\"], [1, 2.519923, \"B17\"], [1, 2.919966, \"B18\"], [1, 1.639945, \"B19\"], [1, 2.999482, \"B17\"], [1, 1.40852, \"B17\"], [1, 3.743988, \"B20\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "819dd833-4d16-4f86-80a8-0f2b2d4337f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_history = [[1, 0, \"B1\"], [1, 1.240046, \"B2\"], [1, 2.007757, \"B4\"], [1, 2.111694, \"B5\"], [1, 2.640466, \"B7\"], [1, 1.207597, \"B7\"], [1, 2.095977, \"B1\"], [1, 4.887838, \"B2\"], [1, 3.360171, \"B6\"], [1, 2.888182, \"B9\"], [1, 2.399382, \"B9\"], [1, 0.623415, \"B10\"], [1, 1.984281, \"B10\"], [1, 3.040082, \"B11\"], [1, 1.968001, \"B11\"], [1, 5.687445, \"B12\"], [1, 1.46414, \"B12\"], [1, 0.999921, \"B13\"], [1, 1.25641, \"B13\"], [1, 1.079489, \"B16\"], [1, 1.960039, \"B18\"], [1, 2.343672, \"B17\"], [1, 1.216535, \"B1\"], [2, 7.495268, \"B2\"], [2, 1.183932, \"B2\"], [2, 4.088051, \"B3\"], [2, 1.055964, \"B3\"], [2, 1.495814, \"B4\"], [2, 2.831986, \"B7\"], [2, 1.09601, \"B7\"], [2, 2.072154, \"B8\"], [2, 3.655571, \"B9\"], [2, 2.919945, \"B9\"], [2, 1.775967, \"B10\"], [2, 1.071762, \"B10\"], [2, 0.927999, \"B11\"], [2, 1.32011, \"B11\"], [2, 5.215865, \"B13\"], [2, 2.511833, \"B13\"], [2, 1.215928, \"B16\"], [2, 2.280026, \"B17\"], [2, 0.487739, \"B19\"], [3, 15.94366, \"B1\"], [3, 1.519849, \"B2\"], [3, 3.784085, \"B3\"], [3, 0.719879, \"B7\"], [3, 5.07186, \"B5\"], [3, 0.839993, \"B4\"], [3, 3.98368, \"B9\"], [3, 0.864322, \"B9\"], [3, 1.287763, \"B10\"], [3, 0.183965, \"B10\"], [3, 2.304302, \"B11\"], [3, 0.183608, \"B11\"], [3, 5.976258, \"B12\"], [3, 0.511672, \"B13\"], [3, 2.624429, \"B17\"], [3, 0.631774, \"B18\"], [3, 1.391534, \"B19\"], [4, 8.303699, \"B1\"], [4, 0.65617, \"B1\"], [4, 0.99196, \"B2\"], [4, 0.775912, \"B2\"], [4, 1.639828, \"B5\"], [4, 1.799983, \"B7\"], [4, 3.112035, \"B9\"], [4, 2.775872, \"B9\"], [4, 1.488142, \"B10\"], [4, 0.648082, \"B10\"], [4, 1.031751, \"B11\"], [4, 1.279784, \"B11\"], [4, 3.103919, \"B12\"], [4, 3.352348, \"B16\"], [4, 3.536015, \"B14\"], [4, 3.103751, \"B17\"], [4, 0.551967, \"B18\"], [4, 2.047521, \"B19\"], [5, 6.40794, \"B1\"], [5, 1.040046, \"B1\"], [5, 1.208045, \"B2\"], [5, 0.735888, \"B2\"], [5, 5.528436, \"B3\"], [5, 1.727946, \"B3\"], [5, 4.087149, \"B5\"], [5, 3.448328, \"B4\"], [5, 0.632083, \"B3\"], [5, 4.27177, \"B8\"], [5, 1.063952, \"B4\"], [5, 2.59978, \"B4\"], [5, 3.543969, \"B11\"], [5, 0.999659, \"B11\"], [5, 1.512174, \"B9\"], [5, 2.839982, \"B15\"], [5, 3.05593, \"B16\"], [5, 0.607875, \"B17\"], [5, 3.240049, \"B18\"], [5, 2.503921, \"B19\"], [5, 3.367925, \"B17\"], [5, 0.319983, \"B17\"], [5, 1.184058, \"B20\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec92037-ffa0-4b2e-9e71-adf312e55941",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_grids = cleaned_arrays[962]\n",
    "trial_history = trial_history\n",
    "\n",
    "# Function to append data to the DataFrame\n",
    "def append_to_dataframe(ui_grid, trial_history):\n",
    "    global df\n",
    "    grid_str = str(ui_grid.tolist())\n",
    "    new_row = pd.DataFrame({'ui_grid': [grid_str], 'trial_history': [trial_history]})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Append sample data\n",
    "append_to_dataframe(selected_grids, trial_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26cb36-a6a1-4357-8aa0-b9d97cc26e1d",
   "metadata": {},
   "source": [
    "### write to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceec561e-e77b-4a24-890a-429e0c762e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "13c08599-45cc-4308-84a8-7f8a1df1b410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_grids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19530a7-e35c-4d47-8a66-f0ab54187686",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196357c5-7eae-461f-be45-7c869d16f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utilities:\n",
    "    def __init__(self, ui_elements_grid, association_data):\n",
    "        self.ui_elements_grid = ui_elements_grid\n",
    "        self.associations = self.parse_associations(association_data)\n",
    "    \n",
    "    def parse_associations(self, association_data):\n",
    "        associations = {}\n",
    "        for group in association_data:\n",
    "            for element in group:\n",
    "                associations[element] = group\n",
    "        return associations\n",
    "    \n",
    "    def get_click_distribution(self, history, normalize=True):\n",
    "        frequency = {}\n",
    "        total_clicks = 0\n",
    "        indexed_history = []\n",
    "\n",
    "        # Initialize frequency dictionary\n",
    "        for row in self.ui_elements_grid:\n",
    "            for command in row:\n",
    "                if command != 0:\n",
    "                    frequency[command] = 0\n",
    "\n",
    "        # Calculate frequency of each command\n",
    "        for trial in history:\n",
    "            _, _, command = trial\n",
    "            if command != 0:\n",
    "                if command in frequency:\n",
    "                    frequency[command] += 1\n",
    "                else:\n",
    "                    frequency[command] = 1\n",
    "                total_clicks += 1\n",
    "\n",
    "        # Normalize frequencies if required\n",
    "        if normalize:\n",
    "            for command in frequency.keys():\n",
    "                frequency[command] = round(frequency[command] / total_clicks, 3)\n",
    "\n",
    "        # Create indexed history\n",
    "        for trial in history:\n",
    "            _, _, command = trial\n",
    "            if command != 0:\n",
    "                command_position = np.argwhere(self.ui_elements_grid == command)\n",
    "                if command_position.size > 0:\n",
    "                    indexed_history.append([command, command_position[0].tolist()])\n",
    "\n",
    "        return frequency, total_clicks, indexed_history\n",
    "    \n",
    "    def get_activations(self, indexed_history, session_interval, duration_between_clicks):\n",
    "        activations = {} # Activation per target per location\n",
    "        session_click_length = 20 # Clicks per session\n",
    "        total_clicks = len(indexed_history) # Total clicks from indexed history\n",
    "        total_sessions = math.ceil(total_clicks / session_click_length) # Number of sessions so far\n",
    "\n",
    "        for i in range(total_clicks):\n",
    "            session = math.ceil((i + 1) / session_click_length) # Session index\n",
    "            item = indexed_history[i][0]\n",
    "            position = tuple(indexed_history[i][1]) # Position from indexed history\n",
    "\n",
    "            if item not in activations:\n",
    "                activations[item] = {position: 0} # Item has not been seen yet. Add to dictionary\n",
    "            if position not in activations[item]:\n",
    "                activations[item][position] = 0 # Item not seen at this position yet. Add to item's dictionary\n",
    "\n",
    "            time_difference = duration_between_clicks * (total_clicks - i) + (total_sessions - session) * session_interval # Difference between time now and time of click\n",
    "            activations[item][position] += pow(time_difference, -0.5)\n",
    "\n",
    "        # Flatten activations to get mean value and element position\n",
    "        activations = {k: (np.mean(list(v.values())), list(v.keys())[0]) for k, v in activations.items()}\n",
    "        return activations\n",
    "    \n",
    "    def get_association_matrix(self):\n",
    "        rows, cols = self.ui_elements_grid.shape\n",
    "        association_matrix = np.zeros((rows * cols, rows * cols))\n",
    "        \n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if self.ui_elements_grid[i, j] in self.associations:\n",
    "                    for k in range(rows):\n",
    "                        for l in range(cols):\n",
    "                            if self.ui_elements_grid[k, l] in self.associations[self.ui_elements_grid[i, j]]:\n",
    "                                association_matrix[i * cols + j, k * cols + l] = 1.0\n",
    "                            else:\n",
    "                                association_matrix[i * cols + j, k * cols + l] = 0.0\n",
    "                else:\n",
    "                    for k in range(rows):\n",
    "                        for l in range(cols):\n",
    "                            association_matrix[i * cols + j, k * cols + l] = 0.0\n",
    "        \n",
    "        return association_matrix\n",
    "\n",
    "    def get_sorted_frequencies(self, frequency):\n",
    "        sorted_frequencies = []\n",
    "        \n",
    "        for row in self.ui_elements_grid:\n",
    "            for item in row:\n",
    "                if item == 0:\n",
    "                    sorted_frequencies.append(0.0)\n",
    "                else:\n",
    "                    sorted_frequencies.append(frequency.get(item, 0.0))\n",
    "                    \n",
    "        return sorted_frequencies\n",
    "\n",
    "\n",
    "\n",
    "    def update_freqdist(self, history, grid, normalize=True):\n",
    "        freqdist = {}\n",
    "        for row in grid:\n",
    "            for command in row:\n",
    "                if command != 0:\n",
    "                    freqdist[command] = 0\n",
    "    \n",
    "        simple_hist = [row[0] for row in history]\n",
    "        for item in simple_hist:\n",
    "            if item == \"\":\n",
    "                continue\n",
    "            if item not in list(freqdist.keys()):\n",
    "                freqdist[item] = 1.\n",
    "            else:\n",
    "                freqdist[item] += 1.\n",
    "    \n",
    "        total_clicks = sum(list(freqdist.values()))\n",
    "    \n",
    "        if normalize:\n",
    "            for command in list(freqdist.keys()):\n",
    "                freqdist[command] = round(freqdist[command] / total_clicks, 3)\n",
    "    \n",
    "        return freqdist\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def update_hist(self, indexed_history, new_grid, number_of_clicks=20):\n",
    "        history = indexed_history.copy()\n",
    "        #print(len(history))\n",
    "            \n",
    "        if number_of_clicks:\n",
    "            clicks_to_add = history[-number_of_clicks:]\n",
    "        \n",
    "            \n",
    "            for item, position in clicks_to_add:\n",
    "                #history.append([item, new_grid_list.index(click)])\n",
    "                #print(new_grid_list.index(item))\n",
    "                result = np.where(new_grid == item)\n",
    "                result_list = list(zip(result[0], result[1]))\n",
    "                history.append([item, result_list])\n",
    "    \n",
    "        freqdist=update_freqdist(history, new_grid)\n",
    "        return freqdist, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9acd9d9-3edb-492a-87ad-13c56d33cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file containing the generated data\n",
    "df = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af957583-e5c3-4305-b280-b4cf8570d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the dataset list\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea4cab7a-6bd7-4062-abfb-d2f309b7a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Parse the grid and trial history from the DataFrame\n",
    "    grid = np.array(eval(row['ui_grid']), dtype=object)\n",
    "    trial_history = eval(row['trial_history'])\n",
    "    \n",
    "    # Initialize the Utilities class with the grid and association data\n",
    "    utilities = Utilities(grid, association_data)\n",
    "    \n",
    "    # Generate sorted frequencies and association matrix using Utilities\n",
    "    frequency, _, indexed_history = utilities.get_click_distribution(trial_history)\n",
    "    sorted_frequencies = utilities.get_sorted_frequencies(frequency)\n",
    "    association_matrix = utilities.get_association_matrix()\n",
    "    \n",
    "    # Convert grid, sorted frequencies, and association matrix to strings for saving\n",
    "    grid_str = str(grid.tolist())\n",
    "    sorted_frequencies_str = str(sorted_frequencies)\n",
    "    association_matrix_str = str(association_matrix.tolist())\n",
    "    \n",
    "    # Append the data to the dataset\n",
    "    dataset.append([grid_str, sorted_frequencies_str, association_matrix_str])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af7cdd7-a78b-4b09-90e1-877aef0e88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame from the dataset\n",
    "training_df = pd.DataFrame(dataset, columns=['ui_grid', 'sorted_frequencies', 'association_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3206b3cc-be53-491a-8e68-b5d49092cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training DataFrame to a CSV file\n",
    "training_df.to_csv('training_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14837dee-17ae-4357-9083-ab3e4050848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "MAX_MENU_ITEMS = 900  # Adjust as needed\n",
    "ENC_VOCAB_SIZE = 6  # Adjust as needed for one-hot encoding\n",
    "\n",
    "def pad(array, size, value=0):\n",
    "    if isinstance(array, np.ndarray) and len(array.shape) == 2:\n",
    "        padded_array = np.full((size, size), value)\n",
    "        min_rows = min(array.shape[0], size)\n",
    "        min_cols = min(array.shape[1], size)\n",
    "        padded_array[:min_rows, :min_cols] = array[:min_rows, :min_cols]\n",
    "        return padded_array\n",
    "    elif isinstance(array, list):\n",
    "        return array + [value] * abs((len(array) - size))\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data type for padding\")\n",
    "\n",
    "# Make sure to update the adj function to handle 2D arrays\n",
    "def adj(vec, value=0):\n",
    "    if isinstance(vec, np.ndarray) and len(vec.shape) == 2:\n",
    "        return pad(vec, MAX_MENU_ITEMS, value)\n",
    "    else:\n",
    "        N = len(vec)\n",
    "        d = MAX_MENU_ITEMS - N\n",
    "        if d < 0:\n",
    "            vec = vec[:MAX_MENU_ITEMS]\n",
    "        elif d > 0:\n",
    "            vec = list(vec) + [value for _ in range(d)]\n",
    "        return np.array(vec)\n",
    "\n",
    "\n",
    "#def onehot_menu(items):\n",
    "#    indices = [int(hash(item) % ENC_VOCAB_SIZE) for item in items]\n",
    "#    one_hot = F.one_hot(torch.tensor(indices), num_classes=ENC_VOCAB_SIZE)\n",
    "#    return one_hot\n",
    "\n",
    "\n",
    "def onehot_menu(items):\n",
    "    enc_menu = [tf.keras.preprocessing.text.one_hot(str(w), ENC_VOCAB_SIZE, filters='') for w in items]\n",
    "    return enc_menu\n",
    "\n",
    "\n",
    "def flatten_grid(grid):\n",
    "    return [str(item) for row in grid for item in row]\n",
    "\n",
    "def parse_user_input(source_grid, source_freq, source_asso, target_grid, target_freq, target_asso):\n",
    "    # Flatten grids to lists of strings\n",
    "    source_menu = flatten_grid(source_grid)\n",
    "    target_menu = flatten_grid(target_grid)\n",
    "\n",
    "    # Encode adapted menu as integers and compute the difference between previous and current menu configuration.\n",
    "    adap_menu = onehot_menu(target_menu)\n",
    "    # Adjust remaining menu items with zeros (reserved value) at the end.\n",
    "    adap_menu = adj(adap_menu, value=[0])\n",
    "\n",
    "    # Ensure that all vectors have the same length.\n",
    "    max_freq_len = max(len(source_freq), len(target_freq))\n",
    "    max_asso_len = max(source_asso.shape[0], target_asso.shape[0])\n",
    "    source_freq = pad(source_freq, max_freq_len)\n",
    "    target_freq = pad(target_freq, max_freq_len)\n",
    "    source_asso = pad(source_asso, max_asso_len)\n",
    "    target_asso = pad(target_asso, max_asso_len)\n",
    "\n",
    "    diff_freq = np.diff([source_freq, target_freq], axis=0).flatten()\n",
    "    diff_asso = np.diff([source_asso, target_asso], axis=0).flatten()\n",
    "\n",
    "    # Ensure there is a change in freq distribution, otherwise `diff_freq` would be always zero.\n",
    "    if np.array_equal(source_freq, target_freq):\n",
    "        diff_freq = source_freq\n",
    "\n",
    "    # The association matrix list is given as a flat vector, so reshape it before padding.\n",
    "    # Notice that we read the number of items BEFORE padding `diff_freq`.\n",
    "    num_rows = len(diff_freq)\n",
    "    num_cols = len(diff_asso) // num_rows\n",
    "    diff_asso = diff_asso.reshape((num_cols, num_rows))\n",
    "    diff_asso = adj(diff_asso, [0] * MAX_MENU_ITEMS)\n",
    "    diff_asso = diff_asso.reshape((MAX_MENU_ITEMS * MAX_MENU_ITEMS,))\n",
    "\n",
    "    return adap_menu, adj(diff_freq), diff_asso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d882e02c-a9af-4caa-98b7-734ed0c8ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the dataset for source and target inputs\n",
    "source_target_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11741379-60de-4f3d-b065-920d25fcafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process pairs of adjacent rows to form source and target inputs\n",
    "for i in range(len(training_df) - 1):\n",
    "    # Extract source and target data\n",
    "    source_row = training_df.iloc[i]\n",
    "    target_row = training_df.iloc[i + 1]\n",
    "    \n",
    "    # Parse the grid, sorted frequencies, and association matrix from strings\n",
    "    source_grid = np.array(eval(source_row['ui_grid']), dtype=object)\n",
    "    source_freq = eval(source_row['sorted_frequencies'])\n",
    "    source_asso = np.array(eval(source_row['association_matrix']), dtype=object)\n",
    "    \n",
    "    target_grid = np.array(eval(target_row['ui_grid']), dtype=object)\n",
    "    target_freq = eval(target_row['sorted_frequencies'])\n",
    "    target_asso = np.array(eval(target_row['association_matrix']), dtype=object)\n",
    "    \n",
    "    # Use the provided function to form the source and target inputs\n",
    "    adap_menu, diff_freq, diff_asso = parse_user_input(\n",
    "        source_grid, source_freq, source_asso, \n",
    "        target_grid, target_freq, target_asso\n",
    "    )\n",
    "    \n",
    "    # Append the data to the source_target_data list\n",
    "    source_target_data.append([adap_menu, diff_freq, diff_asso])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "793d6c65-49ca-4cbd-99f6-8dc8fd677f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the source and target data to a new CSV file\n",
    "source_target_df = pd.DataFrame(source_target_data, columns=['adap_menu', 'diff_freq', 'diff_asso'])\n",
    "source_target_df.to_csv('source_target_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df469e09-7778-4cd3-a816-158dea93f54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(source_target_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67329036-e906-49dd-89e2-6ea0beb5c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the list to a text file\n",
    "with open('my_list.txt', 'w') as file:\n",
    "    for item in source_target_data[0][2]:\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac475a22-e8a7-4d4b-85c6-b4d0dc0665d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PyTorch model architecture\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, num_items, enc_vocab_size=6, extra_features_size=1):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.enc_vocab_size = enc_vocab_size\n",
    "        self.extra_features_size = extra_features_size\n",
    "\n",
    "        # Menu head\n",
    "        self.menu_embedding = nn.Embedding(enc_vocab_size, num_items)\n",
    "        self.menu_flatten = nn.Flatten()\n",
    "        self.menu_dropout = nn.Dropout(0.5)\n",
    "        self.menu_dense = nn.Linear(num_items, num_items // 2)\n",
    "\n",
    "        # Frequency head\n",
    "        self.freq_reshape = lambda x: x.view(-1, num_items, 1)\n",
    "        self.freq_lstm = nn.LSTM(1, num_items, batch_first=True)\n",
    "        self.freq_dropout = nn.Dropout(0.5)\n",
    "        self.freq_dense = nn.Linear(num_items, num_items // 2)\n",
    "\n",
    "        # Association head\n",
    "        self.asso_reshape = lambda x: x.view(-1, num_items, num_items)\n",
    "        self.asso_lstm = nn.LSTM(num_items, num_items * 2, batch_first=True)\n",
    "        self.asso_dropout = nn.Dropout(0.5)\n",
    "        self.asso_dense = nn.Linear(num_items * 2, num_items // 2)\n",
    "\n",
    "        # Combined head\n",
    "        combined_input_size = (num_items // 2) * 3 + extra_features_size\n",
    "        self.serial_dense1 = nn.Linear(combined_input_size, num_items // 2)\n",
    "        self.serial_dropout = nn.Dropout(0.5)\n",
    "        self.serial_output = nn.Linear(num_items // 2, 1)\n",
    "\n",
    "        self.forage_dense1 = nn.Linear(combined_input_size, num_items // 2)\n",
    "        self.forage_dropout = nn.Dropout(0.5)\n",
    "        self.forage_output = nn.Linear(num_items // 2, 1)\n",
    "\n",
    "        self.recall_dense1 = nn.Linear(combined_input_size, num_items // 2)\n",
    "        self.recall_dropout = nn.Dropout(0.5)\n",
    "        self.recall_output = nn.Linear(num_items // 2, 1)\n",
    "\n",
    "    def forward(self, menu_input, freq_input, asso_input, extra_features):\n",
    "        # Menu head\n",
    "        menu = self.menu_embedding(menu_input)\n",
    "        print('Menu embedding:', menu.shape)\n",
    "        menu = self.menu_flatten(menu)\n",
    "        print('Menu flatten:', menu.shape)\n",
    "        menu = self.menu_dropout(menu)\n",
    "        print('Menu dropout:', menu.shape)\n",
    "        menu = self.menu_dense(menu)\n",
    "        print('Menu dense:', menu.shape)\n",
    "\n",
    "        # Frequency head\n",
    "        freq = self.freq_reshape(freq_input)\n",
    "        print('Freq reshape:', freq.shape)\n",
    "        freq, _ = self.freq_lstm(freq)\n",
    "        print('Freq LSTM:', freq.shape)\n",
    "        freq = self.freq_dropout(freq[:, -1, :])  # Take only the last output\n",
    "        print('Freq dropout:', freq.shape)\n",
    "        freq = self.freq_dense(freq)\n",
    "        print('Freq dense:', freq.shape)\n",
    "\n",
    "        # Association head\n",
    "        asso = self.asso_reshape(asso_input)\n",
    "        print('Asso reshape:', asso.shape)\n",
    "        asso, _ = self.asso_lstm(asso)\n",
    "        print('Asso LSTM:', asso.shape)\n",
    "        asso = self.asso_dropout(asso[:, -1, :])  # Take only the last output\n",
    "        print('Asso dropout:', asso.shape)\n",
    "        asso = self.asso_dense(asso)\n",
    "        print('Asso dense:', asso.shape)\n",
    "\n",
    "        # Combine heads\n",
    "        combined = torch.cat([menu, freq, asso, extra_features], dim=1)\n",
    "        print('Combined:', combined.shape)\n",
    "\n",
    "        # Serial tail\n",
    "        serial = self.serial_dense1(combined)\n",
    "        print('Serial dense1:', serial.shape)\n",
    "        serial = self.serial_dropout(serial)\n",
    "        print('Serial dropout:', serial.shape)\n",
    "        serial = self.serial_output(serial)\n",
    "        print('Serial output:', serial.shape)\n",
    "\n",
    "        # Forage tail\n",
    "        forage = self.forage_dense1(combined)\n",
    "        print('Forage dense1:', forage.shape)\n",
    "        forage = self.forage_dropout(forage)\n",
    "        print('Forage dropout:', forage.shape)\n",
    "        forage = self.forage_output(forage)\n",
    "        print('Forage output:', forage.shape)\n",
    "\n",
    "        # Recall tail\n",
    "        recall = self.recall_dense1(combined)\n",
    "        print('Recall dense1:', recall.shape)\n",
    "        recall = self.recall_dropout(recall)\n",
    "        print('Recall dropout:', recall.shape)\n",
    "        recall = self.recall_output(recall)\n",
    "        print('Recall output:', recall.shape)\n",
    "\n",
    "        return serial, forage, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96372b2c-2419-432b-bea1-9df9858f2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the PyTorch model architecture\n",
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, num_items, enc_vocab_size=6, extra_features_size=1):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.enc_vocab_size = enc_vocab_size\n",
    "        self.extra_features_size = extra_features_size\n",
    "\n",
    "        # Menu head\n",
    "        self.menu_embedding = nn.Embedding(enc_vocab_size, num_items)\n",
    "        self.menu_flatten = nn.Flatten()\n",
    "        self.menu_dropout = nn.Dropout(0.5)\n",
    "        self.menu_dense = nn.Linear(num_items * num_items, num_items // 2)\n",
    "\n",
    "        # Frequency head\n",
    "        self.freq_reshape = lambda x: x.view(-1, num_items, 1)\n",
    "        self.freq_lstm = nn.LSTM(1, num_items, batch_first=True)\n",
    "        self.freq_dropout = nn.Dropout(0.5)\n",
    "        self.freq_dense = nn.Linear(num_items, num_items // 2)\n",
    "\n",
    "        # Association head\n",
    "        self.asso_reshape = lambda x: x.view(-1, num_items, num_items)\n",
    "        self.asso_lstm = nn.LSTM(num_items, num_items * 2, batch_first=True)\n",
    "        self.asso_dropout = nn.Dropout(0.5)\n",
    "        self.asso_dense = nn.Linear(num_items * 2, num_items // 2)\n",
    "\n",
    "        # Combined head\n",
    "        combined_input_size = (num_items // 2) * 3 + extra_features_size\n",
    "        self.serial_dense1 = nn.Linear(combined_input_size, num_items // 2)\n",
    "        self.serial_dropout = nn.Dropout(0.5)\n",
    "        self.serial_output = nn.Linear(num_items // 2, 1)\n",
    "\n",
    "        self.forage_dense1 = nn.Linear(combined_input_size, num_items // 2)\n",
    "        self.forage_dropout = nn.Dropout(0.5)\n",
    "        self.forage_output = nn.Linear(num_items // 2, 1)\n",
    "\n",
    "        self.recall_dense1 = nn.Linear(combined_input_size, num_items // 2)\n",
    "        self.recall_dropout = nn.Dropout(0.5)\n",
    "        self.recall_output = nn.Linear(num_items // 2, 1)\n",
    "\n",
    "    def forward(self, menu_input, freq_input, asso_input, extra_features):\n",
    "        # Menu head\n",
    "        print('Input Data:', menu_input.shape)\n",
    "        menu = self.menu_embedding(menu_input)\n",
    "        print('Menu embedding:', menu.shape)\n",
    "        menu = self.menu_flatten(menu)\n",
    "        print('Menu flatten:', menu.shape)\n",
    "        menu = self.menu_dropout(menu)\n",
    "        print('Menu dropout:', menu.shape)\n",
    "        menu = self.menu_dense(menu)\n",
    "        print('Menu dense:', menu.shape)\n",
    "\n",
    "        # Frequency head\n",
    "        freq = self.freq_reshape(freq_input)\n",
    "        print('Freq reshape:', freq.shape)\n",
    "        freq, _ = self.freq_lstm(freq)\n",
    "        print('Freq LSTM:', freq.shape)\n",
    "        freq = self.freq_dropout(freq[:, -1, :])  # Take only the last output\n",
    "        print('Freq dropout:', freq.shape)\n",
    "        freq = self.freq_dense(freq)\n",
    "        print('Freq dense:', freq.shape)\n",
    "\n",
    "        # Association head\n",
    "        asso = self.asso_reshape(asso_input)\n",
    "        print('Asso reshape:', asso.shape)\n",
    "        asso, _ = self.asso_lstm(asso)\n",
    "        print('Asso LSTM:', asso.shape)\n",
    "        asso = self.asso_dropout(asso[:, -1, :])  # Take only the last output\n",
    "        print('Asso dropout:', asso.shape)\n",
    "        asso = self.asso_dense(asso)\n",
    "        print('Asso dense:', asso.shape)\n",
    "\n",
    "        # Combine heads\n",
    "        combined = torch.cat([menu, freq, asso, extra_features], dim=1)\n",
    "        print('Combined:', combined.shape)\n",
    "\n",
    "        # Serial tail\n",
    "        serial = self.serial_dense1(combined)\n",
    "        print('Serial dense1:', serial.shape)\n",
    "        serial = self.serial_dropout(serial)\n",
    "        print('Serial dropout:', serial.shape)\n",
    "        serial = self.serial_output(serial)\n",
    "        print('Serial output:', serial.shape)\n",
    "\n",
    "        # Forage tail\n",
    "        forage = self.forage_dense1(combined)\n",
    "        print('Forage dense1:', forage.shape)\n",
    "        forage = self.forage_dropout(forage)\n",
    "        print('Forage dropout:', forage.shape)\n",
    "        forage = self.forage_output(forage)\n",
    "        print('Forage output:', forage.shape)\n",
    "\n",
    "        # Recall tail\n",
    "        recall = self.recall_dense1(combined)\n",
    "        print('Recall dense1:', recall.shape)\n",
    "        recall = self.recall_dropout(recall)\n",
    "        print('Recall dropout:', recall.shape)\n",
    "        recall = self.recall_output(recall)\n",
    "        print('Recall output:', recall.shape)\n",
    "\n",
    "        return serial, forage, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9282c37-35f2-4478-8eb3-454094837656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the source and target dataset\n",
    "source_target_df = pd.read_csv('source_target_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "961fee6e-4049-4b0e-abe7-bd537b8a323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to numpy arrays\n",
    "adap_menu = np.stack([data[0] for data in source_target_data])\n",
    "diff_freq = np.stack([data[1] for data in source_target_data])\n",
    "diff_asso = np.stack([data[2] for data in source_target_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e74014fa-f3f5-4003-926b-c4a795de3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = diff_freq.shape[1]\n",
    "model = ValueNetwork(num_items, enc_vocab_size=ENC_VOCAB_SIZE, extra_features_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bb93ecd-42c3-4db1-be29-359074eed060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de4fac87-472c-47a7-8401-5fb5ddf505d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "adap_menu_tensor = torch.tensor(adap_menu, dtype=torch.long).squeeze(-1)\n",
    "diff_freq_tensor = torch.tensor(diff_freq, dtype=torch.float32)\n",
    "diff_asso_tensor = torch.tensor(diff_asso, dtype=torch.float32)\n",
    "extra_features_tensor = torch.zeros((adap_menu.shape[0], 1), dtype=torch.float32)  # Dummy extra features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec9e97fa-6e89-4ee4-9cae-d4ec9e64f129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 810000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_asso_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16b3e249-3949-4f22-95d2-de9a481862ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 900])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_freq_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd96fed8-82e3-4740-94f8-dcecb903ffa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 900])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adap_menu_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "099c82da-efc4-43b4-ac8c-c983eca915e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy target values (use actual targets here)\n",
    "target_values = torch.zeros((adap_menu.shape[0], 1), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ce556-ec07-49da-99fc-1d4fb68c96f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data: torch.Size([4, 900])\n",
      "Menu embedding: torch.Size([4, 900, 900])\n",
      "Menu flatten: torch.Size([4, 810000])\n",
      "Menu dropout: torch.Size([4, 810000])\n",
      "Menu dense: torch.Size([4, 450])\n",
      "Freq reshape: torch.Size([4, 900, 1])\n",
      "Freq LSTM: torch.Size([4, 900, 900])\n",
      "Freq dropout: torch.Size([4, 900])\n",
      "Freq dense: torch.Size([4, 450])\n",
      "Asso reshape: torch.Size([4, 900, 900])\n",
      "Asso LSTM: torch.Size([4, 900, 1800])\n",
      "Asso dropout: torch.Size([4, 1800])\n",
      "Asso dense: torch.Size([4, 450])\n",
      "Combined: torch.Size([4, 1351])\n",
      "Serial dense1: torch.Size([4, 450])\n",
      "Serial dropout: torch.Size([4, 450])\n",
      "Serial output: torch.Size([4, 1])\n",
      "Forage dense1: torch.Size([4, 450])\n",
      "Forage dropout: torch.Size([4, 450])\n",
      "Forage output: torch.Size([4, 1])\n",
      "Recall dense1: torch.Size([4, 450])\n",
      "Recall dropout: torch.Size([4, 450])\n",
      "Recall output: torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    serial, forage, recall = model(adap_menu_tensor, diff_freq_tensor, diff_asso_tensor, extra_features_tensor)\n",
    "    #print('done 1')\n",
    "    loss_serial = criterion(serial, target_values)\n",
    "    loss_forage = criterion(forage, target_values)\n",
    "    loss_recall = criterion(recall, target_values)\n",
    "    #print('done 2')\n",
    "\n",
    "    loss = loss_serial + loss_forage + loss_recall\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Save the tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf6384-6d3f-4a4b-a633-437880526b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a96e54-b2dc-4aa9-b9a7-25c83d579607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
