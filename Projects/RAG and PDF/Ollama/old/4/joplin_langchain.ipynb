{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58359d56-dbb3-46bf-990e-1daddcd52e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchainhub\n",
    "!pip install langchain-qdrant\n",
    "!pip install langchain transformers accelerate sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d410316-b435-491d-be66-c6b91e10ff96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'chi21adaptive'...\n",
      "remote: Enumerating objects: 70, done.\u001b[K\n",
      "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
      "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
      "remote: Total 70 (delta 17), reused 53 (delta 10), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (70/70), 370.94 KiB | 2.17 MiB/s, done.\n",
      "Resolving deltas: 100% (17/17), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/aalto-ui/chi21adaptive.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4beac09a-9089-4606-97e5-931995f01493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.document_loaders import JoplinLoader\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "loader = JoplinLoader(access_token=\"0437143735021d70121809d13b5bae5b3f3736ff125320e142b4945c03aee1e5cb57b28665bb53372054cea0beade9df2d39cca9cefd02c388eed46f4894f39e\")\n",
    "\n",
    "\n",
    "data = loader.load()\n",
    "data = filter_complex_metadata(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba9a8502-6bb6-43ea-b0f4-81254102d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in data:\n",
    " old_path_with_txt_extension = doc.metadata[\"source\"]\n",
    " new_path_without_txt_extension = old_path_with_txt_extension.replace(\".txt\", \"\")\n",
    " doc.metadata.update({\"source\": new_path_without_txt_extension})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44b3148e-d7a3-43f9-87ab-3aaf18439301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "#from langchain_community.vectorstores import Qdrant\n",
    "from langchain_qdrant import Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc7ec3dd-1dc3-4939-b1b5-bf2590e27518",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mxbai-embed-large\"\n",
    "embeddings = OllamaEmbeddings(model=model_name,\n",
    " show_progress=True,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df796b2e-f865-448a-a13f-72f0c15aa10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|█████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "OllamaEmbeddings: 100%|███████████████████████████████████████████████████| 64/64 [00:44<00:00,  1.44it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████████████████████████████| 64/64 [00:41<00:00,  1.53it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████████████████████████████| 64/64 [00:34<00:00,  1.84it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████████████████████████████| 64/64 [00:39<00:00,  1.63it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████████████████████████████| 64/64 [00:47<00:00,  1.35it/s]\n",
      "OllamaEmbeddings: 100%|███████████████████████████████████████████████████| 26/26 [00:22<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "#Index new docs to db\n",
    "\n",
    "qdrant = Qdrant.from_documents(\n",
    " data,\n",
    " embeddings,\n",
    " path=\"local_qdrant_joplin\",\n",
    " collection_name=\"my_documents\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da68183-a8ae-4a9b-9607-c37a0ce15f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restore db\n",
    "\n",
    "qdrant = Qdrant.from_existing_collection(\n",
    " embeddings,\n",
    " path=\"local_qdrant_joplin\",\n",
    " collection_name=\"my_documents\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8bdf038-4759-4f9d-bde3-a07e99e509ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(documents):\n",
    "    for doc in documents:\n",
    "        print(doc.metadata)\n",
    "        print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
    "        print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88c901a8-3d39-4f9d-98cf-0226744f7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.prompts.chat import HumanMessagePromptTemplate\n",
    "\n",
    "# LLM from Ollama\n",
    "local_model = \"llama3\"\n",
    "llm = ChatOllama(model=local_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "015a0f95-f455-426a-9383-169ef68608c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|█████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "query = \"what are the groceries list in here\"\n",
    "found_docs = qdrant.similarity_search(query)\n",
    "#pretty_print_docs(found_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd6f9b30-6ee8-477f-8ee9-c7d968a3b567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='- [x] Yogert\\n- [x] Milk\\n- [ ]  Heavy cream\\n- [x] Onions\\n- [x] Bio Paper\\n- [x] Toilet paper\\n- [x] eggs\\n- [x] Tomatoes\\n- [x] Batteries\\n- [x] pickled carrots\\n- [x]  bread\\n- [x]  chicken stock\\n- [x]  shampoo\\n- [x]  coffee\\n- [x]  noodles\\n- [ ]  nestle milk additive\\n- [x]  shampoo\\n- [ ]  Butter \\n- [x]  Pickled Cabbbage\\n- [ ]  vegetables\\n- [x]  onion\\n- [x]  broccoli\\n- [x]  chicken\\n- [x]  toothpaste\\n- [ ]  cereal\\n- [x]  pesto\\n- [ ]  tortilla \\n- [x]  earbuds\\n- [x]  pasta\\n- [x]  shower gell\\n- [x]  ginger\\n- [x]  oil\\n- [x]  spinach\\n- [ ]  cherry tomatoes\\n- [ ]  garlic\\n- [x]  sponge\\n- [ ]  ketchup\\n- [ ]  kitchen towel', metadata={'source': 'joplin://x-callback-url/openNote?id=a9ab7ef1f3b44decb242625f90d3708c', 'folder': 'To-Do', 'title': 'Groceries', 'created_time': '2023-07-01 02:28:20', 'updated_time': '2024-06-16 17:48:16', '_id': '98361c1702674799b9e88ebb8f51b639', '_collection_name': 'my_documents'}),\n",
       " Document(page_content='- [x] chappals\\n- [x] small tins to put spices and coffee \\n- [x] perfume\\n- [ ] toilet paper, sewa, pocket tissue\\n- [x] plate\\n- [ ]  butter knife\\n- [ ]  kitchen knife\\n- [ ]  washing detergent\\n- [x]  bathing brush\\n- [x]  cup\\n- [x]  hand wash\\n- [x]  salt, sugar\\n- [x]  hdmi\\n- [x]  shower-gel\\n', metadata={'source': 'joplin://x-callback-url/openNote?id=f47895fd86fc403aa3ef434638355c87', 'folder': 'personal notes', 'title': 'Things to buy ', 'created_time': '2023-11-01 16:12:03', 'updated_time': '2024-06-16 17:48:12', '_id': '3cbf92d02f154ec5900f28c3ff4491b8', '_collection_name': 'my_documents'}),\n",
       " Document(page_content=\"Danke für deine Bewerbung. Wir freuen uns! Folge dem Link und erfahre wie's weiter geht to.foodora.com/a/01rkqx0\", metadata={'source': 'joplin://x-callback-url/openNote?id=616f05f9bc38440a88aa70c729f1fc48', 'folder': 'personal notes', 'title': 'Foodora', 'created_time': '2023-10-25 09:00:22', 'updated_time': '2023-10-25 09:00:29', '_id': '317a4a83c3724bd697c15e6c5bf719ac', '_collection_name': 'my_documents'}),\n",
       " Document(page_content='Tk healthcare \\nWhatsApp\\nGmail\\nCommerzbank \\nWhatsApp\\n', metadata={'source': 'joplin://x-callback-url/openNote?id=d2b0c4db261844f7a8ce1684ed2d7163', 'folder': 'personal notes', 'title': 'Change Number', 'created_time': '2023-10-06 18:38:01', 'updated_time': '2023-10-06 18:40:24', '_id': '374d1702f9ad4360b79467c8eefe21d7', '_collection_name': 'my_documents'})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481e537-bee0-497e-b2aa-fe500869c0f8",
   "metadata": {},
   "source": [
    "### Implementation 1 (directly from serach docs and not from retreiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ea11517-a1d1-48fa-8d67-1758b947009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "Prompt: ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "#response = chain.invoke({\"question\":query,\"context\":found_docs})\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa125560-add5-4da6-9b2a-b43367daac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here is your groceries list:\n",
      "\n",
      "* Yogurt\n",
      "* Milk\n",
      "* Onions\n",
      "* Bio Paper\n",
      "* Toilet paper\n",
      "* Eggs\n",
      "* Tomatoes\n",
      "* Pickled carrots\n",
      "* Bread\n",
      "* Chicken stock\n",
      "* Shampoo\n",
      "* Coffee\n",
      "* Noodles\n",
      "* Butter\n",
      "* Pickled cabbage\n",
      "* Onion\n",
      "* Broccoli\n",
      "* Chicken\n",
      "* Toothpaste\n",
      "* Pesto\n",
      "* Pasta\n",
      "* Shower gel\n",
      "* Ginger\n",
      "* Oil\n",
      "* Spinach"
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream({\"question\":query,\"context\":found_docs}):\n",
    "    print(chunk, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ae152-cdf6-417c-9de7-1abf6d19d67e",
   "metadata": {},
   "source": [
    "### Implementation 2 (using retreiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74bdfefc-a2df-4363-875b-a96e903a2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cd0c279-b7b2-4c66-994f-0a0ac6121dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    qdrant.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "Prompt: ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "814ef723-18a7-456f-bd6a-9b2f1c3e7cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for prompts\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from typing import List, Tuple\n",
    "from langchain.schema import format_document\n",
    "\n",
    "#Initialte chat_history\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "# Create a memory instance\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\", memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "# Define steps for the chain\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\"),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define templates for prompts\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple]) -> str:\n",
    "    buffer = \"\"\n",
    "    for dialogue_turn in chat_history:\n",
    "        human = \"HumanMessage: \" + dialogue_turn[0]\n",
    "        ai = \"AIMessage: \" + dialogue_turn[1]\n",
    "        buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
    "    return buffer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],        \n",
    "#        \"chat_history\": lambda x: _format_chat_history(x[\"chat_history\"]),\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser(),\n",
    "}\n",
    "\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | llm,\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "\n",
    "# Create the final chain by combining the steps\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c74972b2-dbbc-433f-b8c3-492e36953041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "OllamaEmbeddings: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s]\n",
      "OllamaEmbeddings: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s]\n",
      "OllamaEmbeddings: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s]\n",
      "OllamaEmbeddings: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A policy network and a value network are both neural network models used in reinforcement learning. However, they serve different purposes and have distinct architectures.\n",
      "\n",
      "Policy Networks:\n",
      "\n",
      "Policy networks, also known as actor-critic networks or policy-value networks, are designed to learn the optimal policy for a given task. The goal of a policy network is to maximize the cumulative reward over an episode, while exploring different actions and their corresponding outcomes. In other words, the policy network learns to select the best action given the current state of the environment.\n",
      "\n",
      "The architecture of a policy network typically consists of two main components: an actor and a critic. The actor generates actions based on the current state of the environment, while the critic evaluates the quality of the selected action. The output of the actor is used to make decisions in the real-world environment, while the output of the critic provides a value estimate for each possible action.\n",
      "\n",
      "Value Networks:\n",
      "\n",
      "On the other hand, value networks are designed to learn the optimal value function for a given task. The goal of a value network is to predict the expected return or value of taking a specific action in a particular state of the environment. In other words, the value network learns to estimate the quality of each possible action and its corresponding outcome.\n",
      "\n",
      "The architecture of a value network typically consists of an input layer, one or more hidden layers, and an output layer. The input layer receives the current state of the environment, while the output layer provides a value estimate for each possible action. The hidden layers process the input data to extract relevant features and improve the accuracy of the value estimates.\n",
      "\n",
      "Differences:\n",
      "\n",
      "The main differences between policy networks and value networks lie in their objectives, architectures, and applications.\n",
      "\n",
      "Objective:\n",
      "\n",
      "Policy networks are trained to maximize the cumulative reward over an episode, while value networks are trained to predict the expected return or value of taking a specific action in a particular state of the environment.\n",
      "\n",
      "Architecture:\n",
      "\n",
      "The architecture of policy networks is designed to generate actions based on the current state of the environment, while the architecture of value networks is designed to provide a value estimate for each possible action.\n",
      "\n",
      "Applications:\n",
      "\n",
      "Policy networks are commonly used in applications where the goal is to maximize the cumulative reward over an episode, such as in robotics, game playing, and autonomous driving. Value networks are commonly used in applications where the goal is to predict the expected return or value of taking a specific action in a particular state of the environment, such as in finance, insurance, and risk management.\n",
      "\n",
      "In summary, policy networks and value networks are both important components of reinforcement learning algorithms, but they serve different purposes and have distinct architectures. While policy networks learn the optimal policy for a given task, value networks learn the optimal value function to predict the expected return or value of taking a specific action in a particular state of the environment."
     ]
    }
   ],
   "source": [
    "#stream chain 7\n",
    "\n",
    "input = \"\"\"\n",
    "Is there any diffrence between policy network and value network? why are these used in here?\n",
    "\"\"\"\n",
    "inputs = {\"question\": input, \"chat_history\": chat_history}\n",
    "\n",
    "\n",
    "\n",
    "chunks = []\n",
    "chunks_answer = []\n",
    "for chunk in final_chain.stream(inputs):\n",
    "    chunks.append(chunk)\n",
    "    if 'answer' in chunk:\n",
    "        print(chunk['answer'].content, end='')\n",
    "        chunks_answer.append(chunk['answer'].content)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "#Below code might not work\n",
    "\n",
    "\n",
    "# Save the conversation in memory\n",
    "#generated_answer = chunks['answer']\n",
    "\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=input),\n",
    "    AIMessage(content=chunks_answer),\n",
    "    #AIMessage(content=result[\"answer\"].content),\n",
    "])\n",
    "\n",
    "\n",
    "# Load memory to see the conversation history\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "#memory.save_context(inputs, {\"answer\": generated_answer.content})\n",
    "memory.save_context(inputs, {\"answer\": chunks_answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202854e6-6bf9-4172-a9f4-e2e213edd92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
