{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d5cab6-515e-4dd6-95ae-6393f0c4435c",
   "metadata": {},
   "source": [
    "## Ingesting PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8b999-83ba-484a-9b94-f56c201d2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --q unstructured langchain\n",
    "%pip install --q \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2dcf2cfe-a7aa-4ecf-85e3-f77b9e850514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "removing any unused layers \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5394d61f-906b-4776-b8b5-9f0045c76193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --q chromadb\n",
    "%pip install --q langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39aebbf8-92bf-42e5-951e-40bb458852d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   \tID          \tSIZE  \tMODIFIED      \n",
      "llama3:latest          \t71a106a91016\t4.7 GB\t19 hours ago \t\n",
      "llava:latest           \t8dd30f6b0cb1\t4.7 GB\t3 hours ago  \t\n",
      "nomic-embed-text:latest\t0a109f422b47\t274 MB\t9 seconds ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a975d62-d0f0-499b-8172-47bb46b4b652",
   "metadata": {},
   "source": [
    "### Program Starts From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0e2f74-7c4b-4665-8d87-bc00656f31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import OnlinePDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e6f5e-b476-4161-a2d5-a2c1d9668e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use method 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93273bfb-3b43-4382-8ad2-6539f2d21bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method-1:upload single document\n",
    "\n",
    "local_path = \"book2.pdf\"\n",
    "\n",
    "# Local PDF file uploads\n",
    "if local_path:\n",
    "  loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "  data = loader.load()\n",
    "else:\n",
    "  print(\"Upload a PDF file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9919ca33-7da2-41a6-bb1a-439ff63f7055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:04<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#method-2:upload multiple documents from a folder\n",
    "#note: pypdf also records title, page numeber etc required by chain-5\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "\n",
    "#loader = DirectoryLoader('/home/tom/Python/Tools/RAG and PDF/docs', glob=\"**/*.pdf\", loader_cls=UnstructuredPDFLoader, show_progress=True)\n",
    "loader = DirectoryLoader('/home/tom/Python/Tools/RAG and PDF/docs', glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader, show_progress=True)\n",
    "data = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38119195-9c91-4e58-aa46-8a74244032af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technologies of Additive Manufacturing\\n\\nDr Matthias Hien\\n\\nLiterature:\\n\\n1. Gibson: Additive Manufacturing Technologies 2. https://www.engineersgarage.com/articles/3d-printing- processes-binder-jetting\\n\\n3. https://www.voxeljet.com/materialien/kunststoff/pmma-ppb- ppc-ppc2/\\n\\n4. https://www.youtube.com/watch?v=maO3XxB1imU 5. S. Nachum, J. Vogt, F. Raether : Additive Manufacturing of Ceramics: Stereolithography versus Binder Jetting\\n\\n6. C.Hauser:IMAGE TRANSFORMATIONS AND PRINTING OF PLASTER LAYERS IN SPIRAL GROWTH MANUFACTURING\\n\\nAdditive Manufacturing Technologies\\n\\nBinder Jetting\\n\\nBinder Jetting\\n\\n1. Introduction 2. Materials 3. Process Variations 4. Process Benefits and Drawback\\n\\nBinder Jetting\\n\\n1. Introduction\\n\\nBinder jetting is copyrighted by the name 3DP technology. It was developed at Massachusetts Institute of Technology (MIT) in 1993. Later on, the license of the technology was obtained by Z Corporation in 1995.\\n\\nhttps://www.engineersgar age.com/articles/3d- printing-processes-binder- jetting\\n\\nBinder Jetting\\n\\n1. Introduction\\n\\n3 D Priniting (3DP) : A Binder is printed onto a powder bed to form a part cross section. Because it uses powder it was briefly discussed in the section for powder bed fusion (PBF). Difference for most PBF concepts: A laser is used to melt or sinter powder to form a part cross section.\\n\\nhttps://www.engineersgar age.com/articles/3d- printing-processes-binder- jetting\\n\\nBinder Jetting\\n\\n1. Introduction\\n\\nDifference between MJ and BJ: All of the part material will be jetted through the head Not like binder jetting where only the binder is suspense through the head. Therefore only a small portion of the part material will be delivered through the print head. The majority of part material will be delivered through the powder bed.\\n\\nBinder Jetting\\n\\n2. Material\\n\\nCommercially available materials 3D System\\n\\n3D System\\n\\nBinder Jetting\\n\\n2. Material\\n\\nCommercially available materials 3D System\\n\\n3D System\\n\\nBinder Jetting\\n\\n2. Material\\n\\nCommercially available materials 3D System\\n\\n3D System\\n\\nBinder Jetting\\n\\n2. Material\\n\\nCommercially available materials:\\n\\nInfiltration is the process of applying a liquid resin to a printed part to provide strength and specific properties. The lower viscosity of our infiltrants allows the resin to soak into the porous surface without leaving a thick film on the top surface.\\n\\nThe diagram illustrates the open matrix of green printed Z Corp. parts. In the second drawing, the infiltrant is represented as the yellow coating applied to the surface of the matrix. Finally, the third diagram shows how the infiltrant is drawn into the part, sealing the surface area and improving the appearance and strength of the part.\\n\\nBinder Jetting\\n\\n2. Material\\n\\nCommercially available materials:\\n\\nThe graph shows the flexural strength of all the powders relative to each infiltrant option. The flexural test measures the force required to bend a test specimen.\\n\\n3D System\\n\\nBinder Jetting\\n\\n2. Material\\n\\nCommercially available materials:\\n\\n3D System\\n\\nBinder Jetting\\n\\n2. Material PMMA\\n\\nCommercially available materials:\\n\\nhttps://www.voxeljet.com/materialien/k unststoff/pmma-ppb-ppc-ppc2/\\n\\nBinder Jetting Binder Jetting\\n\\n2. Material PMMA\\n\\nCommercially available materials:\\n\\nhttps://www.voxeljet.com/materialien/k unststoff/pmma-ppb-ppc-ppc2/\\n\\nBinder Jetting\\n\\n2. Material\\n\\nPMMA\\n\\nCommercially available materials:\\n\\n3D plastic printing enables cost-effective and time-saving production of investment casting patterns and design models. The models are produced step by step by applying a particle material in layers and selectively bonding it with a binder. PMMA (polymethyl methacrylate), an acrylic plastic, is used as the particulate material. Large formats with a length of one meter, a width of 60 centimeters and a height of 50 centimeters are possible.\\n\\nBinder Jetting\\n\\nPRACTICAL BENEFITS\\n\\nCost-effective production of investment casting patterns: without the need for complex and expensive tool production. •Complex components: virtually no limit to geometry. •True-to-detail models due to a print resolution of up to 600 dpi. •High dimensional stability: no danger of heat distortion - even with large 3D patterns. •Surface finishing: wax infiltration for smoother investment castings or epoxy resin for improved strength of display models. •No shell breakage in investment casting due to negative thermal expansion coefficients. •Environmentally friendly: almost 100% of loose, unprinted material is reusable. FUNCTIONAL PROPERTIES OF PLASTIC FOR 3D PRINTING: •Ideal for investment casting patterns, optimal burnout properties of the PMMA particle material. •High print resolution and detail accuracy. •Filigree designs possible: wall thicknesses (from only 0.6 cm) can be implemented. •Economical production of batch sizes of 1 as well as small series\\n\\nBinder Jetting\\n\\n2. Material\\n\\nSand\\n\\nCommercially available materials:\\n\\nSAND: FAST, ECONOMICAL CASTING MOLDS\\n\\nsand molds and cores for metal casting\\n\\nTo achieve this, silica sand is built up layer by layer until the desired part has been constructed. The layers of sand are selectively bonded using a binder, ensuring stability and flexural strength. This fast process is perfect for manufacturing prototypes or optimizing parts. Large formats up to 4 metres long, 2 metres wide and one metre high are also possible\\n\\nSand\\n\\nBinder Jetting\\n\\nBinder Jetting\\n\\n2. Material Sand\\n\\nCommercially available materials:\\n\\nBinder Jetting\\n\\n2. Material\\n\\nSand\\n\\nCommercially available materials:\\n\\nSEVERAL ADVANTAGES\\n\\nFast and flexible: with 3D printing, tools and parts can be optimised quickly and prototypes can be created much more easily.\\n\\nEconomical production: complex sand molds and cores created using additive manufacturing. Expensive tool production is not necessary.\\n\\nGeometrical freedom: Undercuts can be easily realized, resulting in more complex parts than with conventional methods.\\n\\nHigh resolution print heads ensure particularly accurate sand molds and cores.\\n\\nEasy to combine: 3D-printed sand cores can be combined with traditional molds.\\n\\nSimple core removal: Thanks to the low binder content, the behavior during outgassing and core removal is comparable to traditional processes.\\n\\nBinder Jetting\\n\\n2. Material\\n\\nCeramics\\n\\nCommercially available materials:\\n\\nCERAMICS\\n\\nThe models are produced by applying ceramic particle material in fine layers and selectively bonding it with a binder. “Green parts” are subject to thermal decomposition prior sintering to remove the polymer binder.\\n\\nFinally, the components are sintered in the furnace by increasing the temperature. Density around 67%\\n\\nAt the end the parts will be infiltrated or glazed if necessary\\n\\nBinder Jetting\\n\\n2. Material\\n\\nCeramics\\n\\nCERAMICS\\n\\nGeneral: Infiltrant can be Metals First Ceramic trials were with Alumina, Silica, Titanium dioxide\\n\\nHIP was needed\\n\\nIncreased density to 99.2% after HIP\\n\\nBronze\\n\\nStainless steel\\n\\nS. Nachum, J. Vogt, F. Raether : Additive Manufacturing of Ceramics: Stereolithography versus Binder Jetting\\n\\nBinder Jetting\\n\\n2. Material\\n\\nCeramics\\n\\nCommercially available materials:\\n\\nTayloring of specific powders and binders, individually to customer needs\\n\\nProcessing of powders with an average grain size between 40 - 200 µm, preferably between 50 - 70 µm\\n\\nThe extensive voxeljet product portfolio offers ideal scalability with building envelopes up to 1000 x 600 x 500 mm\\n\\nBinder jetting offers to process a variety of materials Geometric freedom provides an enlarged surface area and thus weight reduction and performance improvements of the components\\n\\nApplications include the medical, automotive and aviation industries, , but also the B2C sector\\n\\n•Depending on the powder selected, unprinted powder material is re-usable and recyclable\\n\\n2. Material\\n\\nCommercially available materials:\\n\\nBase Material\\n\\nPlaster\\n\\nStarch\\n\\nPMMA\\n\\nBinder Material\\n\\nWater based\\n\\nWater\\n\\nPolyPor B&C\\n\\nSand\\n\\nResin\\n\\nCeramics/ Metals\\n\\nPolymer binder\\n\\n3.\\n\\nBinder Jetting\\n\\nProcess Variations\\n\\nMost comercially available instruments work like schematic below:\\n\\n3.\\n\\nBinder Jetting\\n\\nProcess Variations\\n\\nAs size of platform varies from a few cm to a few meters. Powder supply needs to be addressed.\\n\\nEspecially Voxeljet uses a rail system to deliver sand as it can weigh a few hundred pounds. And cranes are used to transport parts and molds.\\n\\n3.\\n\\nBinder Jetting\\n\\nProcess Variations\\n\\nContinous printing for parts that are larger than the AM machine:\\n\\nLinear translation (Voxeljet 2013) • Spiral growth manufacturing ( Researchers at Liverpool, UK)\\n\\nhttps://www.youtube.com/watch?v=maO 3XxB1imU\\n\\nBinder Jetting\\n\\n3.\\n\\nProcess Variations\\n\\nLinear translation (Voxeljet 2013)\\n\\nNo restriction to length-continous\\n\\nPrinthead: 600dpi Layerthicknes: 150-400µm\\n\\n500mm\\n\\n850 mm\\n\\nBinder Jetting\\n\\n3.\\n\\nProcess Variations\\n\\nSpiral growth manufacturing\\n\\n2 is the cylindrical built chamber\\n\\nPlates 10,8,14 and 23 do not rotate\\n\\nPlate 14 supports the built chamber and slides up and down\\n\\n24 is for powder bed supply print heads will be inside\\n\\nBinder Jetting\\n\\n3.\\n\\nProcess Variations\\n\\nSpiral growth manufacturing\\n\\nC.Hauser:IMAGE TRANSFORMATIONS AND PRINTING OF PLASTER LAYERS IN SPIRAL GROWTH MANUFACTURING\\n\\n3.\\n\\nBinder Jetting\\n\\nProcess Variations\\n\\nSpiral growth manufacturing\\n\\nC.Hauser:IMAGE TRANSFORMATIONS AND PRINTING OF PLASTER LAYERS IN SPIRAL GROWTH MANUFACTURING\\n\\nBinder Jetting\\n\\n3.\\n\\nProcess Variations\\n\\nSpiral growth manufacturing\\n\\nC.Hauser:IMAGE TRANSFORMATIONS AND PRINTING OF PLASTER LAYERS IN SPIRAL GROWTH MANUFACTURING\\n\\nBinder Jetting\\n\\n4. Process Benefits and Drawback\\n\\nBenefits:\\n\\nDrawback\\n\\nLow cost\\n\\nPoorer accuracy vs MJ\\n\\nHigh speed (faster than MJ\\n\\nPoorer surface finish vs MJ\\n\\n• but extra step to add powder)\\n\\nless volume to dispense\\n\\nScalability\\n\\n\\n\\nInfiltration is typically needed\\n\\n•\\n\\nIncrease density Increase mechanical stability\\n\\nMaterial compositions that are not possible can be done with binder\\n\\nSlurries with higher solids loading are possible to produce • Continuous printing possible'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview first page\n",
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2faacc1-be29-4d52-a46e-94f5b5b8e728",
   "metadata": {},
   "source": [
    "## Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a39856-0cc0-4ebe-8024-9db32455a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad040e2-3abe-4e23-abb9-951b223b9262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and chunk \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45efa4-6b1c-4c9c-889e-5fdf7a4c2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can create a db or load from existing database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb11c92-e732-4a88-8f57-57a19b38e383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# Add documents to vector database in addition to persistant directory (execute this or the one below)\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True),\n",
    "    collection_name=\"local-rag\",\n",
    "    persist_directory=\"./chroma_db_pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "113a1a71-2016-4873-9984-9466c00397c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from existing persistent directory (execute this or the one above)\n",
    "\n",
    "vector_db = Chroma(\n",
    "    persist_directory=\"./chroma_db_pdf\",\n",
    "    embedding_function=OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True),\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec338c4-f282-462f-b0a0-c1899538eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584412a-bca7-48d7-b06d-8d674be30230",
   "metadata": {},
   "source": [
    "## Search relevant docs - Using Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2cd4bf5-a84f-4d3a-adbe-ccf723de19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs a similarity check and returns the top K embeddings\n",
    "# that are similar to the question's embeddings\n",
    "retriever = vector_db.as_retriever(search_type=\"mmr\",       \n",
    "                                        search_kwargs={\"k\": 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233b712-559f-4471-9792-8aef4816343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_relevant_docs = retriever.get_relevant_documents(\n",
    "    \"Binder Jetting\"\n",
    ")\n",
    "\n",
    "for doc in retrieved_relevant_docs:\n",
    "    print(doc.page_content)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eadf50-2f3d-4420-8858-94e9c1682ffa",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1d6ceeb-6883-4688-b923-e771c2b2cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM from Ollama\n",
    "local_model = \"llama3\"\n",
    "llm = ChatOllama(model=local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e6f3e07-95f3-45a2-80fc-4f196c135d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af364202-b666-49c2-ad97-2cc4e424e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf1b69-aed8-4a59-bc0d-fcb4ec78c672",
   "metadata": {},
   "source": [
    "### Use chain of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f4949-c461-45df-8365-54e1b734d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain1 - Original (maybe not good for multiple documents?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb1f308f-8472-4506-9517-d79b61d408f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410a07a-cafd-49bc-ab66-69be3c112bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain2: With history and Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7942d90-470f-44a6-8c0b-9811fa73ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory \n",
    "memory = ConversationBufferMemory(input_key=\"question\",\n",
    "                                   memory_key=\"history\",\n",
    "                                   return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7f601c3-cff4-49c8-9ba6-4cf1abb1cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"\n",
    "### System:\n",
    "You are an AI assistant that follows instructions extremely well. Help as much as you can.\n",
    "### User:\n",
    "You are a research assistant for an artificial intelligence student. Use only the following information to answer user queries:\n",
    "Context= {context}\n",
    "History = {history}\n",
    "Question= {question}\n",
    "### Assistant:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=custom_prompt_template,\n",
    "                        input_variables=[\"question\", \"context\", \"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0412d73c-c06b-438b-99c9-83926521394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "                      llm=llm, chain_type='stuff',\n",
    "                      retriever = retriever,\n",
    "                      return_source_documents = True,\n",
    "                      chain_type_kwargs = {\"verbose\": False,\n",
    "                                           \"prompt\": prompt,\n",
    "                                           \"memory\": memory  \n",
    "                                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c37b96-9102-4cb5-b6cd-0dfcb345bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain3: with sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f0da5fc-0fd1-4b23-a7c0-ffea0c57f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa1b24-0b06-429f-b6ef-b5f097ce62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain4: Original chain (Chain1) Modifies for sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4cfe9-6873-486c-99fa-b19ddf9461e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory \n",
    "memory = ConversationBufferMemory(input_key=\"question\",\n",
    "                                   memory_key=\"history\",\n",
    "                                   return_messages=True)\n",
    "\n",
    "\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "#    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])), history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"))    \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ef114-e5e1-46a7-b1c5-37b2a5abf918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b4529e-217a-4106-8758-cf05c627b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory \n",
    "memory = ConversationBufferMemory(input_key=\"question\",\n",
    "                                   memory_key=\"history\",\n",
    "                                   return_messages=True)\n",
    "\n",
    "\n",
    "#this chain can be also run with format_docs from chain 5\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    \"\"\"Convert Documents to a single string.:\"\"\"\n",
    "    formatted = [\n",
    "        f\"Article Title: {doc.metadata['title']}\\nArticle Snippet: {doc.page_content}\"\n",
    "        for doc in docs\n",
    "    ]\n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(formatted)\n",
    "\n",
    "\n",
    "format = itemgetter(\"docs\") | RunnableLambda(format_docs)\n",
    "# subchain for generating an answer once we've done retrieval\n",
    "answer = prompt | llm | StrOutputParser()\n",
    "# complete chain that calls wiki -> formats docs to string -> runs answer subchain -> returns just the answer and retrieved docs.\n",
    "chain = (\n",
    "    RunnableParallel(question=RunnablePassthrough(), docs=retriever)\n",
    "    .assign(context=format)\n",
    "    .assign(answer=answer)\n",
    "    .pick([\"answer\", \"docs\", \"memory\"]) # you can remove \"docs\" if not needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14149c5-abb4-4182-bbfc-502e1815554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffb53d-486b-4a3c-9922-f4317f47a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for prompts\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from typing import List, Tuple\n",
    "from langchain.schema import format_document\n",
    "\n",
    "# Create a memory instance\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")\n",
    "\n",
    "# Define steps for the chain\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define templates for prompts\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser(),\n",
    "}\n",
    "\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | llm,\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "\n",
    "# Create the final chain by combining the steps\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4f2fc-4ff7-4b81-935b-2d4daa3dfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain 7 (Best to use this one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7dc3f3-0c2d-4837-9ac2-9276d41e108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for prompts\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from typing import List, Tuple\n",
    "from langchain.schema import format_document\n",
    "\n",
    "#Initialte chat_history\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "# Create a memory instance\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\", memory_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "# Define steps for the chain\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\"),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define templates for prompts\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple]) -> str:\n",
    "    buffer = \"\"\n",
    "    for dialogue_turn in chat_history:\n",
    "        human = \"HumanMessage: \" + dialogue_turn[0]\n",
    "        ai = \"AIMessage: \" + dialogue_turn[1]\n",
    "        buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
    "    return buffer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],        \n",
    "#        \"chat_history\": lambda x: _format_chat_history(x[\"chat_history\"]),\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser(),\n",
    "}\n",
    "\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | llm,\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "\n",
    "# Create the final chain by combining the steps\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb1c77-ea4d-45ee-94b9-21b8bc3b1afb",
   "metadata": {},
   "source": [
    "### Diplay results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d743f6a-e552-4df9-9864-c1c70884cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain1\n",
    "\n",
    "#Enter your question in the bracket and press enter\n",
    "chain.invoke(input(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0556e141-7844-498b-b2bb-b20356a2569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what would be its disadvantages?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.59it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.03it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.06it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.93it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.85it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.56it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.40it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.58it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.24it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.16it/s]\n",
      "OllamaEmbeddings: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While Binder Jetting has many advantages, it also has some limitations and potential drawbacks. Some of the primary disadvantages include:\n",
      "\n",
      "1. **Limited part resolution**: The layer thickness and powder size can limit the achievable part resolution, making it challenging to produce parts with small features or high-zirconia ceramic.\n",
      "2. **Binder removal required**: After printing, the binder must be removed through a process like washing or solvent evaporation, which can be time-consuming and may not always be 100% effective.\n",
      "3. **Part density and strength**: The part's density and strength might be compromised if the binding agent is not evenly distributed or if there are air pockets within the powder bed.\n",
      "4. **Material limitations**: Although Binder Jetting allows for various metal and ceramic powders, some materials may not work well with the process or exhibit reduced properties compared to other AM methods.\n",
      "5. **High energy consumption**: The printing process requires a significant amount of energy for heating and processing the binder, which can increase production costs and environmental concerns.\n",
      "6. **Tooling requirements**: Depending on the part's complexity and size, tooling may be required to hold the part in place during printing, adding additional cost and complexity.\n",
      "7. **Limited color options**: Binder Jetting typically works with monochromatic powders, limiting the color palette for aesthetic applications or those requiring specific visual properties.\n",
      "8. **Potential powder reactivity**: Certain metal powders can react with air, moisture, or other chemicals, which may affect their performance or lead to part degradation over time.\n",
      "\n",
      "These limitations and potential drawbacks should be considered when evaluating Binder Jetting as a viable production method for your application.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/home/tom/Python/Tools/RAG and PDF/docs/3.pdf\n",
      "/home/tom/Python/Tools/RAG and PDF/docs/2.pdf\n",
      "/home/tom/Python/Tools/RAG and PDF/docs/3.pdf\n",
      "/home/tom/Python/Tools/RAG and PDF/docs/6.pdf\n",
      "/home/tom/Python/Tools/RAG and PDF/docs/4.pdf\n"
     ]
    }
   ],
   "source": [
    "#Invoke Chain 2 and Chain 3\n",
    "\n",
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])\n",
    "\n",
    "\n",
    "# break it down\n",
    "llm_response = qa_chain.invoke(input(\"\"))\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf43a8f-ace5-43d5-9d64-f5b29f5d6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invoke Chain 4\n",
    "\n",
    "rag_chain_with_source.invoke(input(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f4f1c-576d-4e73-ac96-7f96034ccdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invoke chain 6\n",
    "\n",
    "input = \"what advantages does personas have?\"\n",
    "inputs = {\"question\": input, \"chat_history\": chat_history}\n",
    "result = final_chain.invoke(inputs)\n",
    "# Save the conversation in memory\n",
    "generated_answer = result['answer']\n",
    "\n",
    "# Load memory to see the conversation history\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "memory.save_context(inputs, {\"answer\": generated_answer.content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97298a-3fd6-4da0-a1b8-32c4121a2525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invoke chain 7\n",
    "\n",
    "input = \"what are their advantages?\"\n",
    "inputs = {\"question\": input, \"chat_history\": chat_history}\n",
    "result = final_chain.invoke(inputs)\n",
    "# Save the conversation in memory\n",
    "generated_answer = result['answer']\n",
    "\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=input),\n",
    "    AIMessage(content=result[\"answer\"].content),\n",
    "])\n",
    "\n",
    "\n",
    "# Load memory to see the conversation history\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "memory.save_context(inputs, {\"answer\": generated_answer.content})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f044f-7b80-4085-9983-2abe1c37173e",
   "metadata": {},
   "source": [
    "### Streaming results (Migh not retain context unlike the revoke method (chain 6 and 7 retain context though))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb35c6a-ab9b-4b58-9990-ea90bea702ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note streaming not possible with retreivalQA which is chain 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b871ab-0d88-44c5-a753-c39a4b2167eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streaming-method1 (chain 1)\n",
    "\n",
    "chunks = []\n",
    "for chunk in chain.stream(\"In 3D printing metal, what are the three major contributors to surface roughness\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdd0f2-585d-4624-ba4c-aabe1e3dabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streaming-method2 (chain 1)\n",
    "\n",
    "chunks = []\n",
    "async for chunk in model.astream(\"In 3D printing metal, what are the three major contributors to surface roughness\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f47ef-3f6e-4b43-8eeb-d47639b6be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streaming method3 (chain 4 and 5)\n",
    "\n",
    "output = {}\n",
    "curr_key = None\n",
    "for chunk in chain.stream(\"In 3D printing metal, what are the three major contributors to surface roughness\"):\n",
    "    for key in chunk:\n",
    "        if key not in output:\n",
    "            output[key] = chunk[key]\n",
    "        else:\n",
    "            output[key] += chunk[key]\n",
    "        if key != curr_key:\n",
    "            print(f\"\\n\\n{key}: {chunk[key]}\", end=\"\", flush=True)\n",
    "        else:\n",
    "            print(chunk[key], end=\"\", flush=True)\n",
    "        curr_key = key\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfd4de-9e7c-4816-9e01-9d9634d5c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stream chain 6\n",
    "\n",
    "\n",
    "input = \"what advantages does personas have?\"\n",
    "inputs = {\"question\": input, \"chat_history\": chat_history}\n",
    "\n",
    "\n",
    "chunks = []\n",
    "for chunk in final_chain.stream(inputs):\n",
    "    chunks.append(chunk)\n",
    "    if 'answer' in chunk:\n",
    "        print(chunk['answer'].content, end='')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "#Below code might not work\n",
    "\n",
    "# Save the conversation in memory\n",
    "generated_answer = chunks['answer']\n",
    "\n",
    "# Load memory to see the conversation history\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "memory.save_context(inputs, {\"answer\": generated_answer.content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fee86-3ec1-4c1c-8d3a-9731e71de9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stream chain 7\n",
    "\n",
    "input = \"what are their disadvantages?\"\n",
    "inputs = {\"question\": input, \"chat_history\": chat_history}\n",
    "\n",
    "\n",
    "\n",
    "chunks = []\n",
    "for chunk in final_chain.stream(inputs):\n",
    "    chunks.append(chunk)\n",
    "    if 'answer' in chunk:\n",
    "        print(chunk['answer'].content, end='')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "#Below code might not work\n",
    "\n",
    "\n",
    "# Save the conversation in memory\n",
    "#generated_answer = chunks['answer']\n",
    "\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=input),\n",
    "    AIMessage(content=chunks_answer),\n",
    "    #AIMessage(content=result[\"answer\"].content),\n",
    "])\n",
    "\n",
    "\n",
    "# Load memory to see the conversation history\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "#memory.save_context(inputs, {\"answer\": generated_answer.content})\n",
    "memory.save_context(inputs, {\"answer\": chunks_answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfe79f21-48aa-4820-aa9f-79f3d1a0a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all collections in the db\n",
    "vector_db.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
