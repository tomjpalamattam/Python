{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e599d86-42e5-46da-9976-393c6e3f6626",
   "metadata": {},
   "source": [
    "## SPLIT INTO PDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de3661a6-bdf0-4183-8582-66dd8e15871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "def split_pdf(input_pdf, output_folder):\n",
    "    reader = PdfReader(input_pdf)\n",
    "    \n",
    "    for i, page in enumerate(reader.pages):\n",
    "        writer = PdfWriter()\n",
    "        writer.add_page(page)\n",
    "        \n",
    "        output_path = f\"{output_folder}/page_{i+1}.pdf\"\n",
    "        with open(output_path, \"wb\") as output_file:\n",
    "            writer.write(output_file)\n",
    "        \n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e84138-0c3a-4610-ac4d-a845620bd1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: extracted/page_1.pdf\n",
      "Saved: extracted/page_2.pdf\n",
      "Saved: extracted/page_3.pdf\n",
      "Saved: extracted/page_4.pdf\n",
      "Saved: extracted/page_5.pdf\n",
      "Saved: extracted/page_6.pdf\n",
      "Saved: extracted/page_7.pdf\n",
      "Saved: extracted/page_8.pdf\n",
      "Saved: extracted/page_9.pdf\n",
      "Saved: extracted/page_10.pdf\n",
      "Saved: extracted/page_11.pdf\n",
      "Saved: extracted/page_12.pdf\n",
      "Saved: extracted/page_13.pdf\n",
      "Saved: extracted/page_14.pdf\n",
      "Saved: extracted/page_15.pdf\n",
      "Saved: extracted/page_16.pdf\n",
      "Saved: extracted/page_17.pdf\n",
      "Saved: extracted/page_18.pdf\n",
      "Saved: extracted/page_19.pdf\n",
      "Saved: extracted/page_20.pdf\n",
      "Saved: extracted/page_21.pdf\n",
      "Saved: extracted/page_22.pdf\n",
      "Saved: extracted/page_23.pdf\n",
      "Saved: extracted/page_24.pdf\n",
      "Saved: extracted/page_25.pdf\n",
      "Saved: extracted/page_26.pdf\n",
      "Saved: extracted/page_27.pdf\n",
      "Saved: extracted/page_28.pdf\n",
      "Saved: extracted/page_29.pdf\n",
      "Saved: extracted/page_30.pdf\n",
      "Saved: extracted/page_31.pdf\n",
      "Saved: extracted/page_32.pdf\n",
      "Saved: extracted/page_33.pdf\n",
      "Saved: extracted/page_34.pdf\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "split_pdf(\"ml.pdf\", \"extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc507e7-7c60-474f-9b1d-3489089252cb",
   "metadata": {},
   "source": [
    "### SPLIT INTO JPEGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e035cc5-f852-45dd-b5dc-5c15edab282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "def pdf_to_jpeg(input_pdf, output_folder, dpi=300):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    images = convert_from_path(input_pdf, dpi=dpi)\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        image_path = f\"{output_folder}/page_{i+1}.jpg\"\n",
    "        image.save(image_path, \"JPEG\")\n",
    "        print(f\"Saved: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb16da46-9af5-4900-9559-7a41a4f76b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: extracted-images/page_1.jpg\n",
      "Saved: extracted-images/page_2.jpg\n",
      "Saved: extracted-images/page_3.jpg\n",
      "Saved: extracted-images/page_4.jpg\n",
      "Saved: extracted-images/page_5.jpg\n",
      "Saved: extracted-images/page_6.jpg\n",
      "Saved: extracted-images/page_7.jpg\n",
      "Saved: extracted-images/page_8.jpg\n",
      "Saved: extracted-images/page_9.jpg\n",
      "Saved: extracted-images/page_10.jpg\n",
      "Saved: extracted-images/page_11.jpg\n",
      "Saved: extracted-images/page_12.jpg\n",
      "Saved: extracted-images/page_13.jpg\n",
      "Saved: extracted-images/page_14.jpg\n",
      "Saved: extracted-images/page_15.jpg\n",
      "Saved: extracted-images/page_16.jpg\n",
      "Saved: extracted-images/page_17.jpg\n",
      "Saved: extracted-images/page_18.jpg\n",
      "Saved: extracted-images/page_19.jpg\n",
      "Saved: extracted-images/page_20.jpg\n",
      "Saved: extracted-images/page_21.jpg\n",
      "Saved: extracted-images/page_22.jpg\n",
      "Saved: extracted-images/page_23.jpg\n",
      "Saved: extracted-images/page_24.jpg\n",
      "Saved: extracted-images/page_25.jpg\n",
      "Saved: extracted-images/page_26.jpg\n",
      "Saved: extracted-images/page_27.jpg\n",
      "Saved: extracted-images/page_28.jpg\n",
      "Saved: extracted-images/page_29.jpg\n",
      "Saved: extracted-images/page_30.jpg\n",
      "Saved: extracted-images/page_31.jpg\n",
      "Saved: extracted-images/page_32.jpg\n",
      "Saved: extracted-images/page_33.jpg\n",
      "Saved: extracted-images/page_34.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "pdf_to_jpeg(\"ml.pdf\", \"extracted-images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eee7c9-a33e-4b5f-92e5-43b8a0ade4b0",
   "metadata": {},
   "source": [
    "## INITIAL VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a3d22-7236-48df-ba5e-6bbce2a771bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9799ae52-5d04-4edf-95a2-70cda7f69c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def append_human(self, text):\n",
    "        self.messages.append({\"role\": \"human\", \"content\": text})\n",
    "\n",
    "    def append_ai(self, text):\n",
    "        self.messages.append({\"role\": \"ai\", \"content\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "744e59b2-ceb6-4093-961b-28e7c29397e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(state):\n",
    "    \"\"\"Formats the chat history into a proper prompt.\"\"\"\n",
    "    # The system message could provide some instructions or context\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an assistant that answers questions based on the given context. \"\n",
    "                   \"Here is some context from previous conversations, and you should try to provide an accurate answer.\"\n",
    "    }\n",
    "\n",
    "    # Return the system message and the entire chat history (human and AI messages)\n",
    "    return [system_message] + state.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eebdebbf-15e8-4e9e-8b86-01cde5f04ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = State()\n",
    "prompt = create_prompt(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45158b9e-cd85-48d7-83f3-40675bdefc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.append_human(\"You are an AI agent that will be used to extract the words in a pdf file split into multiple pages\")\n",
    "state.append_ai(\"Ok Got it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94608c78-68cd-4df2-ae89-01213ae35f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'human',\n",
       "  'content': 'You are an AI agent that will be used to extract the words in a pdf file split into multiple pages'},\n",
       " {'role': 'ai', 'content': 'Ok Got it'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e0c414d-be6e-49a4-b3f2-59ac60caa2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have the capability to transcribe text from an image. However, I can provide some general information about the context of the conversation.\n",
      "\n",
      "context appears to be related to a discussion about machine learning or data science, as evidenced by the mention of terms such as \"MAE\", \"MSE\", \"RMSE\", \"RAE\", \"ASE\", and \"R^2\". These terms are commonly used in the field of machine learning to evaluate the performance of models.\n",
      "\n",
      "context or clarify what specific question you would like me to answer, I would be happy to try and assist you."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"extracted-images/page_3.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "question = \"transcribe the text?\"\n",
    "\n",
    "\n",
    "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "headers = {\n",
    "  \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "  \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"meta-llama/llama-3.2-90b-vision-instruct\",\n",
    "#  \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": question + \"Here is some context to previous conversation\" + str(prompt)\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \n",
    "  \"provider\": {\n",
    "      \"order\": [\n",
    "          \"DeepInfra\",          \n",
    "          \"SambaNova\",\n",
    "          \"Fireworks\"          \n",
    "      ]\n",
    "  },    \n",
    "  \"stream\": True\n",
    "}\n",
    "\n",
    "buffer = \"\"\n",
    "full_message = []\n",
    "with requests.post(url, headers=headers, json=payload, stream=True) as r:\n",
    "  for chunk in r.iter_content(chunk_size=1024, decode_unicode=True):\n",
    "    buffer += chunk\n",
    "    while True:\n",
    "      try:\n",
    "        # Find the next complete SSE line\n",
    "        line_end = buffer.find('\\n')\n",
    "        if line_end == -1:\n",
    "          break\n",
    "\n",
    "        line = buffer[:line_end].strip()\n",
    "        buffer = buffer[line_end + 1:]\n",
    "\n",
    "        if line.startswith('data: '):\n",
    "          data = line[6:]\n",
    "          if data == '[DONE]':\n",
    "            break\n",
    "\n",
    "          try:\n",
    "            data_obj = json.loads(data)\n",
    "            content = data_obj[\"choices\"][0][\"delta\"].get(\"content\")\n",
    "            if content:\n",
    "              print(content, end=\"\", flush=True)\n",
    "              full_message.append(content)\n",
    "          except json.JSONDecodeError:\n",
    "            pass\n",
    "      except Exception:\n",
    "        break\n",
    "\n",
    "joined_text = \" \".join(full_message)\n",
    "state.append_human(question)\n",
    "state.append_ai(joined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a27064-86f2-4c83-aee6-de20d9586100",
   "metadata": {},
   "source": [
    "## FINAL VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5286ef5-9fc7-40c5-b06e-9f251fdd152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35d2f59-f493-4930-b1bb-7b1cebef9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "\n",
    "class ChatAgent:\n",
    "    def __init__(self, api_token):\n",
    "        self.state = State()\n",
    "        self.api_token = api_token\n",
    "\n",
    "    def append_message(self, role, text):\n",
    "        \"\"\"Add a message to the chat history.\"\"\"\n",
    "        self.state.append(role, text)\n",
    "\n",
    "    def get_messages(self):\n",
    "        \"\"\"Extract and return the entire chat history.\"\"\"\n",
    "        return self.state.messages       \n",
    "\n",
    "    def encode_image(self, image_path):\n",
    "        \"\"\"Encode an image to base64.\"\"\"\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    def process_prompt(self, question, image_path=None):\n",
    "        \"\"\"\n",
    "        Process a prompt with an optional image.\n",
    "        Args:\n",
    "            question (str): The question or prompt to process.\n",
    "            image_path (str, optional): Path to the image file. Defaults to None.\n",
    "        \"\"\"\n",
    "        # Prepare the payload\n",
    "        payload = {\n",
    "            \"model\": \"google/gemini-2.0-flash-exp:free\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": question + \" Here is some context to previous conversation: \" + str(self.get_messages())}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"provider\": {\"order\": [\"DeepInfra\", \"SambaNova\", \"Fireworks\"]},\n",
    "            \"stream\": True\n",
    "        }\n",
    "\n",
    "        # Add image to payload if provided\n",
    "        if image_path:\n",
    "            base64_image = self.encode_image(image_path)\n",
    "            payload[\"messages\"][0][\"content\"].append(\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "            )\n",
    "\n",
    "        # Send request to the API\n",
    "        url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        buffer = \"\"\n",
    "        full_message = []\n",
    "        with requests.post(url, headers=headers, json=payload, stream=True) as r:\n",
    "            for chunk in r.iter_content(chunk_size=1024, decode_unicode=True):\n",
    "                buffer += chunk\n",
    "                while True:\n",
    "                    line_end = buffer.find('\\n')\n",
    "                    if line_end == -1:\n",
    "                        break\n",
    "\n",
    "                    line = buffer[:line_end].strip()\n",
    "                    buffer = buffer[line_end + 1:]\n",
    "\n",
    "                    if line.startswith('data: '):\n",
    "                        data = line[6:]\n",
    "                        if data == '[DONE]':\n",
    "                            break\n",
    "\n",
    "                        try:\n",
    "                            data_obj = json.loads(data)\n",
    "                            content = data_obj[\"choices\"][0][\"delta\"].get(\"content\")\n",
    "                            if content:\n",
    "                                print(content, end=\"\", flush=True)\n",
    "                                full_message.append(content)\n",
    "                        except json.JSONDecodeError:\n",
    "                            pass\n",
    "\n",
    "        # Update state with the response\n",
    "        joined_text = \" \".join(full_message)\n",
    "        self.append_message(\"human\", question)\n",
    "        self.append_message(\"ai\", joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eaaf2f5-134e-4dd6-ad0f-f9c23cd22ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def append(self, role, text):\n",
    "        self.messages.append({\"role\": role, \"content\": text})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8afb52a-285f-46d9-ad95-3d27ff120b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = ChatAgent(API_TOKEN)\n",
    "\n",
    "# Add initial messages\n",
    "agent.append_message(\"human\", \"You are an AI agent that will be used to extract the words in a pdf file split into multiple pages\")\n",
    "agent.append_message(\"ai\", \"Ok Got it\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b9ec0-5da9-49af-8b4d-a36f0812ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a prompt with an image\n",
    "question = \"Try to Transcribe the text and extract every single word\"\n",
    "image_path = \"extracted-images/page_5.jpg\"  # Replace with your actual image path\n",
    "agent.process_prompt(question, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a04a2-fbce-401c-87db-5d0f3cf20018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through pages 1 to 38\n",
    "question = \"Try to Transcribe the text and extract every single word.\"\n",
    "for page_number in range(1, 34):  # Pages 1 to 38\n",
    "    image_path = f\"extracted-images/page_{page_number}.jpg\"  # Replace with your actual image path format\n",
    "    print(f\"\\nProcessing page {page_number}...\")\n",
    "    agent.process_prompt(question, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513ec54-21c5-4cb5-b6a2-1635861dbe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64309ef3-c1be-4a9a-b891-8be7ea5c4149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
